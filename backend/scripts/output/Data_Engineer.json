[
  {
    "question": "1. What is Pattern Matching in SQL?",
    "answer": "SQL pattern matching provides for pattern search in data if you have no clue as to what that word should be. This kind of SQL query uses wildcards to match a string pattern, rather than writing the exact word. The LIKE operator is used in conjunction withSQL Wildcardsto fetch the required information.",
    "source": "https://www.interviewbit.com/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "2. How to create empty tables with the same structure as another table?",
    "answer": "Creating empty tables with the same structure can be done smartly by fetching the records of one table into a new table using the INTO operator while fixing a WHERE clause to be false for all records. Hence, SQL prepares the new table with a duplicate structure to accept the fetched records but since no records get fetched due to the WHERE clause in action, nothing is inserted into the new table.",
    "source": "https://www.interviewbit.com/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is a Recursive Stored Procedure?",
    "answer": "A stored procedure that calls itself until a boundary condition is reached, is called a recursive stored procedure. This recursive function helps the programmers to deploy the same set of code several times as and when required. Some SQL programming languages limit the recursion depth to prevent an infinite loop of procedure calls from causing a stack overflow, which slows down the system and may lead to system crashes.",
    "source": "https://www.interviewbit.com/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is a Stored Procedure?",
    "answer": "A stored procedure is a subroutine available to applications that access a relational database management system (RDBMS). Such procedures are stored in the database data dictionary. The sole disadvantage of stored procedure is that it can be executed nowhere except in the database and occupies more memory in the database server. It also provides a sense of security and functionality as users who can't access the data directly can be granted access via stored procedures.",
    "source": "https://www.interviewbit.com/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is Collation? What are the different types of Collation Sensitivity?",
    "answer": "Collation refers to a set of rules that determine how data is sorted and compared. Rules defining the correct character sequence are used to sort the character data. It incorporates options for specifying case sensitivity, accent marks, kana character types, and character width. Below are the different types of collation sensitivity:",
    "source": "https://www.interviewbit.com/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "6. What are the differences between OLTP and OLAP?",
    "answer": "OLAPstands forOnline Analytical Processing, a class of software programs that are characterized by the relatively low frequency of online transactions. Queries are often too complex and involve a bunch of aggregations. For OLAP systems, the effectiveness measure relies highly on response time. Such systems are widely used for data mining or maintaining aggregated, historical data, usually in multi-dimensional schemas.",
    "source": "https://www.interviewbit.com/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "8. What is User-defined function? What are its various types?",
    "answer": "The user-defined functions in SQL are like functions in any other programming language that accept parameters, perform complex calculations, and return a value. They are written to use the logic repetitively whenever required. There are two types of SQL user-defined functions:",
    "source": "https://www.interviewbit.com/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "9. What is a UNIQUE constraint?",
    "answer": "A UNIQUE constraint ensures that all values in a column are different. This provides uniqueness for the column(s) and helps identify each row uniquely. Unlike primary key, there can be multiple unique constraints defined per table. The code syntax for UNIQUE is quite similar to that of PRIMARY KEY and can be used interchangeably.",
    "source": "https://www.interviewbit.com/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is SQL?",
    "answer": "SQL (Structured Query Language) is a standard programming language used to communicate withrelational databases. It allows users to create, read, update, and delete data, and provides commands to definedatabase schemaand manage database security.",
    "source": "https://www.geeksforgeeks.org/sql/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "2. What is a database?",
    "answer": "Adatabaseis anorganized collection of datastored electronically, typically structured in tables with rows and columns. It is managed by adatabase management system(DBMS), which allows for efficientstorage,retrieval, andmanipulationof data.",
    "source": "https://www.geeksforgeeks.org/sql/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "3. What are the main types of SQL commands?",
    "answer": "SQL commands are broadly classified into:",
    "source": "https://www.geeksforgeeks.org/sql/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is the difference between CHAR and VARCHAR2 data types?",
    "answer": "Aprimary keyis a unique identifier for each record in a table. It ensures that no two rows have the same value in the primary key column(s), and it does not allow NULL values.",
    "source": "https://www.geeksforgeeks.org/sql/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is a primary key?",
    "answer": "Aprimary keyis a unique identifier for each record in a table. It ensures that no two rows have the same value in the primary key column(s), and it does not allow NULL values.",
    "source": "https://www.geeksforgeeks.org/sql/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is a foreign key?",
    "answer": "Aforeign keyis a column (or set of columns) in one table that refers to the primary key in another table. It establishes and enforces a relationship between the two tables, ensuring data integrity.",
    "source": "https://www.geeksforgeeks.org/sql/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "7. What is the purpose of the DEFAULT constraint?",
    "answer": "TheDEFAULT constraintassigns a default value to a column when no value is provided during anINSERT operation. This helps maintain consistent data and simplifies data entry.",
    "source": "https://www.geeksforgeeks.org/sql/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "8. What is normalization in databases?",
    "answer": "Normalizationis the process of organizing data in a database toreduce redundancyandimprove data integrity. This involves dividing large tables into smaller, related tables and defining relationships between them to ensure consistency and avoid anomalies.",
    "source": "https://www.geeksforgeeks.org/sql/sql-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is data engineering?",
    "answer": "Data engineering is the practice of designing, building, and maintaining systems for collecting, storing, and analyzing large volumes of data. It involves creating data pipelines, optimizing data storage, and ensuring data quality and accessibility fordata scientistsand analysts.",
    "source": "https://www.geeksforgeeks.org/data-engineering/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are the main responsibilities of a data engineer?",
    "answer": "The main responsibilities of a data engineer include:",
    "source": "https://www.geeksforgeeks.org/data-engineering/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is the difference between a data engineer and a data scientist?",
    "answer": "While both roles work with data, their focus and responsibilities differ:",
    "source": "https://www.geeksforgeeks.org/data-engineering/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is a data pipeline?",
    "answer": "A data pipeline is a series of processes that move data from various sources to a destination system, often involving transformation and processing steps along the way. It ensures that data flows smoothly from its origin to where it's needed for analysis or other purposes.",
    "source": "https://www.geeksforgeeks.org/data-engineering/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "5. What are some common challenges in data engineering?",
    "answer": "Common challenges in data engineering include:",
    "source": "https://www.geeksforgeeks.org/data-engineering/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is a relational database?",
    "answer": "A relational database is a type of database that organizes data into tables with predefined relationships between them. It uses SQL (Structured Query Language) for managing and querying the data.",
    "source": "https://www.geeksforgeeks.org/data-engineering/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "7. What are the main differences between SQL and NoSQL databases?",
    "answer": "Preparing for a data engineering interview means understanding topics like data modeling, ETL processes, and database management. Practicing common interview questions will help you show your skills and knowledge. Keeping up with the latest trends will make you more confident and ready for your interview and your data engineering career.",
    "source": "https://www.geeksforgeeks.org/data-engineering/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "8. What is normalization in database design?",
    "answer": "Normalization is the process of organizing data in a database to reduce redundancy and improve data integrity. It involves breaking down larger tables into smaller, more focused tables and establishing relationships between them.",
    "source": "https://www.geeksforgeeks.org/data-engineering/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is SQL?",
    "answer": "SQL means Structured Query Language and is used to communicate with relational databases. It proposes a standardized way to interact with databases, allowing users to perform various operations on the data, including retrieval, insertion, updating, and deletion.",
    "source": "https://www.simplilearn.com/top-sql-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are the different types of SQL commands?",
    "answer": "SELECT: Retrieves data from a database.",
    "source": "https://www.simplilearn.com/top-sql-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is a primary key in SQL?",
    "answer": "It is a unique identifier for each record in a table. It ensures that each row in the table has a distinct and non-null value in the primary key column. Primary keys enforce data integrity and create relationships between tables.",
    "source": "https://www.simplilearn.com/top-sql-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is a foreign key?",
    "answer": "Foreign keyis a field in one table referencing the primary key in another. It establishes a relationship between the two tables, ensuring data consistency and enabling data retrieval across tables.",
    "source": "https://www.simplilearn.com/top-sql-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is a JOIN in SQL, and what are its types?",
    "answer": "AJOIN operationmerges information from two or more tables by utilizing a common column that links them together. Various types of JOINs exist, like INNER JOIN, LEFT JOIN, RIGHT JOIN, and FULL JOIN. These JOIN variations dictate the manner in which data from the involved tables is paired and retrieved.",
    "source": "https://www.simplilearn.com/top-sql-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "Did You Know? ð",
    "answer": "Professionals with advanced SQL skills, such as database administrators and database architects, receive a median annual pay of $117,450, and the job growth outlook is 8% in the coming years. (Source:ÂU.S. Bureau of Labor Statistics)",
    "source": "https://www.simplilearn.com/top-sql-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "7. What do you mean by a NULL value in SQL?",
    "answer": "A NULL value in SQL represents the absence of data in a column. It is not the same as an empty string or zero; it signifies that the data is missing or unknown. NULL values can be used in columns with optional data or when the data is unavailable.",
    "source": "https://www.simplilearn.com/top-sql-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "9. What is a database?",
    "answer": "Adatabaseis a systematically organized collection of data arranged into tables composed of rows and columns. Its primary purpose is to efficiently store, manage, and retrieve data.",
    "source": "https://www.simplilearn.com/top-sql-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "2. What data masking features are accessible in Azure?",
    "answer": "Data masking in Azure is crucial for data security. It restricts crucial and sensitive information to certain groups of users.",
    "source": "https://www.simplilearn.com/azure-data-engineer-interview-questions-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "3. What do you understand about Polybase?",
    "answer": "Polybase supports T-SQL and optimizes data ingestion into PDW. It lets developers query external data from the supported data stores regardless of their storage architecture.",
    "source": "https://www.simplilearn.com/azure-data-engineer-interview-questions-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "4. What do you understand about reserved capacity in Azure?",
    "answer": "Microsoft offers a reserved capacity option for Azure storage to optimize costs. Considering the reservation period on the Azure cloud, the reserved storage offers customers a specific capacity amount. Azure Data Lake and Block Blobs are available to store Gen 2 data in a standard storage account.",
    "source": "https://www.simplilearn.com/azure-data-engineer-interview-questions-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "5. How can you ensure compliance and data security with Azure Data Services?",
    "answer": "Implementing Azure Active Directory ensures data security by identifying RBAC and allowing management to restrict access based on the principle of the least privilege. Azure Policy is also used to enforce compliance requirements and organizational standards. For GDPR compliance, Azure compliance offerings are leveraged, ensuring data practices align with EU standards.",
    "source": "https://www.simplilearn.com/azure-data-engineer-interview-questions-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "Did You Know? ð",
    "answer": "For this question, elaborate on your experience with Azure Databricks, Azure Data Factory, orAzure Synapse Analytics.",
    "source": "https://www.simplilearn.com/azure-data-engineer-interview-questions-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "7. How did you handle processing and data transformation in Azure?",
    "answer": "For this question, elaborate on your experience with Azure Databricks, Azure Data Factory, orAzure Synapse Analytics.",
    "source": "https://www.simplilearn.com/azure-data-engineer-interview-questions-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "9. How did you approach high availability and disaster recovery in Azure?",
    "answer": "For the scenario, elaborate on the importance of high availability and disaster recovery planning.",
    "source": "https://www.simplilearn.com/azure-data-engineer-interview-questions-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "10. What was your experience with data integration in Azure?",
    "answer": "Discuss your experience with Logic Apps or Azure Data Factory for data integration.Â",
    "source": "https://www.simplilearn.com/azure-data-engineer-interview-questions-article",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is SQL, and what is its purpose in data analysis?",
    "answer": "SQL (Structured Query Language)is a standard language for managing and manipulating relational databases. It allows analysts to query, update, and manage data effectively, which is crucial for data analysis tasks.",
    "source": "https://www.geeksforgeeks.org/data-science/sql-questions-for-data-analyst-interview/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "4. How do you filter records in SQL? Provide an example.",
    "answer": "Use theWHEREclause to filter records based on specific conditions.",
    "source": "https://www.geeksforgeeks.org/data-science/sql-questions-for-data-analyst-interview/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is the purpose of theHAVINGclause? How does it differ fromWHERE?",
    "answer": "HAVINGis used to filter groups after aggregation, whileWHEREfilters rows before aggregation.",
    "source": "https://www.geeksforgeeks.org/data-science/sql-questions-for-data-analyst-interview/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "7. How do you sort the results of a query?",
    "answer": "Use theORDER BYclause to sort results in ascending or descending order.",
    "source": "https://www.geeksforgeeks.org/data-science/sql-questions-for-data-analyst-interview/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "9. What is the difference betweenINNER JOINandLEFT JOIN?",
    "answer": "INNER JOINreturns rows with matching values in both tables, whileLEFT JOINreturns all rows from the left table and matched rows from the right table, with unmatched rows from the right table filled with NULLs.",
    "source": "https://www.geeksforgeeks.org/data-science/sql-questions-for-data-analyst-interview/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "10. How do you find the top 5 highest sales amounts?",
    "answer": "Example:\"SELECT amount FROM sales ORDER BY amount DESC LIMIT 5;\"",
    "source": "https://www.geeksforgeeks.org/data-science/sql-questions-for-data-analyst-interview/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "11. What is a subquery, and how can you use it in theWHEREclause?",
    "answer": "A subquery is a query within another query used to perform operations based on the results of the outer query.",
    "source": "https://www.geeksforgeeks.org/data-science/sql-questions-for-data-analyst-interview/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "13. How do you calculate the average of a column?",
    "answer": "Use theAVG()function to calculate the average value.",
    "source": "https://www.geeksforgeeks.org/data-science/sql-questions-for-data-analyst-interview/",
    "role": "Data Engineer",
    "skill": "SQL",
    "search_strategy": "direct"
  },
  {
    "question": "1.  What is __init__?",
    "answer": "__init__is a contructor method in Python and is automatically called to allocate memory when a new object/instance is created. All classes have a__init__method associated with them. It helps in distinguishing methods and attributes of a class from local variables.",
    "source": "https://www.interviewbit.com/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What is the difference between Python Arrays and lists?",
    "answer": "Arrays in python can only contain elements of same data types i.e., data type of array should be homogeneous. It is a thin wrapper around C language arrays and consumes far less memory than lists.",
    "source": "https://www.interviewbit.com/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. Explain how can you make a Python Script executable on Unix?",
    "answer": "Script file must begin with#!/usr/bin/env python",
    "source": "https://www.interviewbit.com/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What is slicing in Python?",
    "answer": "As the name suggests, ‘slicing’ is taking parts of.",
    "source": "https://www.interviewbit.com/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is docstring in Python?",
    "answer": "Documentation string or docstring is a multiline string used to document a specific code segment.",
    "source": "https://www.interviewbit.com/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What are unit tests in Python?",
    "answer": "Unit test is a unit testing framework of Python.",
    "source": "https://www.interviewbit.com/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What is the use of self in Python?",
    "answer": "Selfis used to represent the instance of the class. With this keyword, you can access the attributes and methods of the class in python. It binds the attributes with the given arguments. self is used in different places and often thought to be a keyword. But unlike in C++, self is not a keyword in Python.",
    "source": "https://www.interviewbit.com/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. What are global, protected and private attributes in Python?",
    "answer": "Globalvariables are public variables that are defined in the global scope. To use the variable in the global scope inside a function, we use theglobalkeyword.",
    "source": "https://www.interviewbit.com/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. Is Python a compiled language or an interpreted language?",
    "answer": "Please remember one thing, whether a language is compiled or interpreted or both is not defined in the language standard. In other words, it is not a properly of a programming language. Different Python distributions (or implementations) choose to do different things (compile or interpret or both).  However the most common implementations like CPython do both compile and interpret, but in different stages of its execution process.",
    "source": "https://www.geeksforgeeks.org/python/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. How can you concatenate two lists in Python?",
    "answer": "We can concatenate two lists in Python using the +operator or theextend()method.",
    "source": "https://www.geeksforgeeks.org/python/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. How do you floor a number in Python?",
    "answer": "To floor a number in Python, you can use the math.floor() function, which returns the largest integer less than or equal to the given number.",
    "source": "https://www.geeksforgeeks.org/python/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is the difference between / and // in Python?",
    "answer": "/ represents precise division (result is a floating point number) whereas // represents floor division (result is an integer). For Example:",
    "source": "https://www.geeksforgeeks.org/python/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. Is Indentation Required in Python?",
    "answer": "Yes,indentationis required in Python. A Python interpreter can be informed that a group of statements belongs to a specific block of code by using Python indentation. Indentations make the code easy to read for developers in all programming languages but in Python, it is very important to indent the code in a specific order.",
    "source": "https://www.geeksforgeeks.org/python/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. Can we Pass a function as an argument in Python?",
    "answer": "Yes, Several arguments can be passed to a function, including objects, variables (of the same or distinct data types) and functions.Functions can be passedas parameters to other functions because they are objects. Higher-order functions are functions that can take other functions as arguments.",
    "source": "https://www.geeksforgeeks.org/python/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What is a dynamically typed language?",
    "answer": "Here, the type of x changes at runtime based on the assigned value hence it shows dynamic nature of Python.",
    "source": "https://www.geeksforgeeks.org/python/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. What is pass in Python?",
    "answer": "Here, fun() does nothing, but the code stays syntactically correct.",
    "source": "https://www.geeksforgeeks.org/python/python-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is the difference betweenisand==in Python?",
    "answer": "Here are the most commonly used Python libraries in data science:",
    "source": "https://www.geeksforgeeks.org/data-science/50-python-interview-questions-for-data-science/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What are some of the most common Python libraries that are used in data science?",
    "answer": "Here are the most commonly used Python libraries in data science:",
    "source": "https://www.geeksforgeeks.org/data-science/50-python-interview-questions-for-data-science/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is NumPy, and why is it important for data science?",
    "answer": "NumPy is a Python library for numerical computing, offering efficient handling of large arrays and matrices. It's crucial for data science due to its:",
    "source": "https://www.geeksforgeeks.org/data-science/50-python-interview-questions-for-data-science/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. How do we create a NumPy array?",
    "answer": "We can create a NumPy array usingnumpy.array(), passing a list or tuple as input.",
    "source": "https://www.geeksforgeeks.org/data-science/50-python-interview-questions-for-data-science/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What are list comprehensions, and how are they useful in data science?",
    "answer": "List comprehensionsprovide a concise way to create lists.  They allow us to generate a new list by applying an expression to each item in an existing iterable, optionally filtering elements based on a condition.",
    "source": "https://www.geeksforgeeks.org/data-science/50-python-interview-questions-for-data-science/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. How can we remove duplicates from a list in Python, and why is this important in data science?",
    "answer": "We can remove duplicates by converting the list to a set. This is important in data science for ensuring that datasets are clean and free from redundant entries before analysis.",
    "source": "https://www.geeksforgeeks.org/data-science/50-python-interview-questions-for-data-science/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What is Pandas, and why do we use it in data science?",
    "answer": "In data science,Pandasis essential for working with large datasets, performing data wrangling and conducting exploratory data analysis (EDA). Its intuitive syntax and wide range of functions make it an invaluable tool for handling time-series data, missing values and more.",
    "source": "https://www.geeksforgeeks.org/data-science/50-python-interview-questions-for-data-science/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. How do we read a CSV file in Pandas?",
    "answer": "To read a CSV file in Pandas, we use theread_csvfunction:",
    "source": "https://www.geeksforgeeks.org/data-science/50-python-interview-questions-for-data-science/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is the difference between a Shallow Copy and a Deep Copy?",
    "answer": "The key difference between a shallow copy and a deep copy is how they handle references within the copied object.",
    "source": "https://www.simplilearn.com/tutorials/python-tutorial/python-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. How is Multithreading achieved in Python?",
    "answer": "Multithreading in Python is achieved using thethreading module, which allows you to run multiple threads (smaller units of a process) concurrently. However, due to the Global Interpreter Lock (GIL), Python threads do not run in true parallelism for CPU-bound tasks. Still, they can be helpful in I/O-bound operations like file handling, network requests, or database queries.",
    "source": "https://www.simplilearn.com/tutorials/python-tutorial/python-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What advantage does the NumPy array have over a Nested list?",
    "answer": "The NumPy array offers several advantages over Pythonâs nested lists, making it more efficient for numerical and scientific computations:",
    "source": "https://www.simplilearn.com/tutorials/python-tutorial/python-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What are Pickling and Unpickling?",
    "answer": "Converting a Python object hierarchy to a byte stream is called pickling.",
    "source": "https://www.simplilearn.com/tutorials/python-tutorial/python-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. How is Memory managed in Python?",
    "answer": "Python has a private heap space that stores all the objects. The Python memory manager regulates various aspects of this heap, such as sharing, caching,segmentation, and allocation. The user cannot control the heap; only the Python interpreter has access.",
    "source": "https://www.simplilearn.com/tutorials/python-tutorial/python-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. Are arguments in Python passed by value or by reference?",
    "answer": "Python passes arguments by reference. Any changes made within a function are reflected in the original object.",
    "source": "https://www.simplilearn.com/tutorials/python-tutorial/python-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. How would you generate Random numbers in Python?",
    "answer": "In Python, you can generate random numbers using the random module for basic random number generation or the numpy library for more advanced use cases.",
    "source": "https://www.simplilearn.com/tutorials/python-tutorial/python-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. What does the // Operator do?",
    "answer": "In Python, the / operator performs division and returns the quotient in the float.",
    "source": "https://www.simplilearn.com/tutorials/python-tutorial/python-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What are the differences between supervised and unsupervised learning?",
    "answer": "Uses known and labeled data as input",
    "source": "https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. How is logistic regression done?",
    "answer": "Logistic regression measures the relationship between the dependent variable (our label of what we want to predict) and one or more independent variables (our features) by estimating probability using its underlying logistic function (sigmoid).",
    "source": "https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. How do you build a random forest model?",
    "answer": "Arandom forestis built up of several decision trees. If you split the data into different packages and make a decision tree in each of the different data groups, the random forest brings all those trees together.",
    "source": "https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. How can you avoid overfitting your model?",
    "answer": "Overfitting refers to a model that is only set for a very small amount of data and ignores the bigger picture. There are three main methods to avoidoverfitting:",
    "source": "https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What feature selection methods are used to select the right variables?",
    "answer": "There are two main methods for feature selection, i.e., filter and wrapper methods.",
    "source": "https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. You are given a data set consisting of variables with more than 30 percent missing values. How will you deal with them?",
    "answer": "The following are ways to handle missing data values:",
    "source": "https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. For the given points, how will you calculate the Euclidean distance in Python?",
    "answer": "The Euclidean distance can be calculated as follows:",
    "source": "https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "11. What are dimensionality reduction and its benefits?",
    "answer": "TheDimensionality reductionrefers to the process of converting a data set with vast dimensions into data with fewer dimensions (fields) to convey similar information concisely.Â",
    "source": "https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What are the industrial benefits of PySpark?",
    "answer": "These days, almost every industry makes use of big data to evaluate where they stand and grow. When you hear the term big data, Apache Spark comes to mind. Following are the industry benefits of using PySpark that supports Spark:",
    "source": "https://www.interviewbit.com/pyspark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What is PySpark?",
    "answer": "PySpark can be installed using PyPi by using the command:",
    "source": "https://www.interviewbit.com/pyspark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is PySpark UDF?",
    "answer": "UDF stands for User Defined Functions. In PySpark, UDF can be created by creating a python function and wrapping it with PySpark SQL’s udf() method and using it on the DataFrame or SQL. These are generally created when we do not have the functionalities supported in PySpark’s library and we have to use our own logic on the data. UDFs can be reused on any number of SQL expressions or DataFrames.",
    "source": "https://www.interviewbit.com/pyspark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What are the types of PySpark’s shared variables and why are they useful?",
    "answer": "Whenever PySpark performs the transformation operation using filter(), map() or reduce(), they are run on a remote node that uses the variables shipped with tasks. These variables are not reusable and cannot be shared across different tasks because they are not returned to the Driver. To solve the issue of reusability and sharing, we have shared variables in PySpark. There are two types of shared variables, they are:",
    "source": "https://www.interviewbit.com/pyspark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is SparkSession in Pyspark?",
    "answer": "SparkSession is the entry point to PySpark and is the replacement of SparkContext since PySpark version 2.0. This acts as a starting point to access all of the PySpark functionalities related to RDDs, DataFrame, Datasets etc. It is also a Unified API that is used in replacing the SQLContext, StreamingContext, HiveContext and all other contexts.",
    "source": "https://www.interviewbit.com/pyspark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What do you understand about PySpark DataFrames?",
    "answer": "PySpark DataFrame is a distributed collection of well-organized data that is equivalent to tables of the relational databases and are placed into named columns. PySpark DataFrame has better optimisation when compared to R or python. These can be created from different sources like Hive Tables, Structured Data Files, existing RDDs, external databases etc as shown in the image below:",
    "source": "https://www.interviewbit.com/pyspark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. Is PySpark faster than pandas?",
    "answer": "PySpark supports parallel execution of statements in a distributed environment, i.e on different cores and different machines which are not present in Pandas. This is why PySpark is faster than pandas.",
    "source": "https://www.interviewbit.com/pyspark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What are the advantages of PySpark RDD?",
    "answer": "PySpark RDDs have the following advantages:",
    "source": "https://www.interviewbit.com/pyspark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Python",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is Apache Spark?",
    "answer": "Apache Spark is a unified analytics engine for large-scale data processing. It offers high-level APIs in Java, Scala, Python, and R and an optimized engine that supports general computation graphs for data analysis. Spark is designed for batch and streaming data, making it a versatile framework for big data processing.",
    "source": "https://www.simplilearn.com/top-apache-spark-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "2. How is Apache Spark different from MapReduce?",
    "answer": "Spark processes data in batches as well as in real-time",
    "source": "https://www.simplilearn.com/top-apache-spark-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "3. What are the Key Features of the Spark Ecosystem?",
    "answer": "The Spark Ecosystem is known for its comprehensive features designed to efficiently handle big data processing and analytics. Key features include:",
    "source": "https://www.simplilearn.com/top-apache-spark-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "4. What are the important components of the Spark ecosystem?",
    "answer": "Apache Spark has 3 main categories that comprise itsecosystem. Those are:",
    "source": "https://www.simplilearn.com/top-apache-spark-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "5. Explain what RDD is?",
    "answer": "RDD stands for Resilient Distributed Dataset. Spark's fundamental data structure represents an immutable, distributed collection of objects that can be processed in parallel. RDDs can contain any type of Python, Java, or Scala objects. They are fault-tolerant, as they track the lineage of transformations applied to them, allowing lost data to be recomputed. RDDs support two types of operations: transformations (which create a new RDD) and actions (which return a value to the driver program).",
    "source": "https://www.simplilearn.com/top-apache-spark-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "6. What does DAG refer to in Apache Spark?",
    "answer": "DAG stands for Directed Acyclic Graph. In the context of Apache Spark, a DAG represents a sequence of computations performed on data. When Spark runs an application, it creates a DAG of tasks to be executed, with each node representing an RDD and each edge representing a transformation applied from one RDD to another. This model allows Spark to optimize the execution plan by rearranging computations and minimizing data shuffling. The DAGScheduler divides the graph into stages that can be executed in parallel, significantly optimizing the processing time.",
    "source": "https://www.simplilearn.com/top-apache-spark-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "8. What are receivers in Apache Spark Streaming?",
    "answer": "Receivers in Apache Spark Streaming are components that ingest data from various sources like Kafka, Flume, Kinesis, or TCP sockets. These receivers collect data and store it in Spark's memory for processing. Spark Streaming supports two types of receivers:",
    "source": "https://www.simplilearn.com/top-apache-spark-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "9. What is the difference between repartition and coalesce?",
    "answer": "Repartition: This method increases or decreases the number of partitions in an RDD, DataFrame, or Dataset. It involves a full shuffle of the data, which is costly in terms of performance because it redistributes data across the cluster.",
    "source": "https://www.simplilearn.com/top-apache-spark-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is YARN in Spark?",
    "answer": "YARN is one of the key features provided by Spark that provides a central resource management platform for delivering scalable operations throughout the cluster.",
    "source": "https://www.interviewbit.com/spark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are the features of Apache Spark?",
    "answer": "High Processing Speed: Apache Spark helps in the achievement of a very high processing speed of data by reducing read-write operations to disk. The speed is almost 100x faster while performing in-memory computation and 10x faster while performing disk computation.",
    "source": "https://www.interviewbit.com/spark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is RDD?",
    "answer": "RDD stands for Resilient Distribution Datasets. It is a fault-tolerant collection of parallel running operational elements. The partitioned data of RDD is distributed and immutable. There are two types of datasets:",
    "source": "https://www.interviewbit.com/spark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "4. What does DAG refer to in Apache Spark?",
    "answer": "DAG stands for Directed Acyclic Graph with no directed cycles. There would be finite vertices and edges. Each edge from one vertex is directed to another vertex in asequential manner. The vertices refer to the RDDs of Spark and the edges represent the operations to be performed on those RDDs.",
    "source": "https://www.interviewbit.com/spark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "6. What are receivers in Apache Spark Streaming?",
    "answer": "Receivers are those entities that consume data from different data sources and then move them to Spark for processing. They are created by using streaming contexts in the form of long-running tasks that are scheduled for operating in a round-robin fashion. Each receiver is configured to use up only a single core. The receivers are made to run on various executors to accomplish the task of data streaming. There are two types of receivers depending on how the data is sent to Spark:",
    "source": "https://www.interviewbit.com/spark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "8. What are the data formats supported by Spark?",
    "answer": "Spark supports both the raw files and the structured file formats for efficient reading and processing. File formats like paraquet, JSON, XML, CSV, RC, Avro, TSV, etc are supported by Spark.",
    "source": "https://www.interviewbit.com/spark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "9. What do you understand by Shuffling in Spark?",
    "answer": "The process of redistribution of data across different partitions which might or might not cause data movement across the JVM processes or the executors on the separate machines is known as shuffling/repartitioning. Partition is nothing but a smaller logical division of data.",
    "source": "https://www.interviewbit.com/spark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "10. What is Apache Spark?",
    "answer": "Apache Spark is an open-source framework engine that is known for its speed, easy-to-use nature in the field of big data processing and analysis. It also has built-in modules for graph processing, machine learning, streaming, SQL, etc. The spark execution engine supports in-memory computation and cyclic data flow and it can run either on cluster mode or standalone mode and can access diverse data sources like HBase, HDFS, Cassandra, etc.",
    "source": "https://www.interviewbit.com/spark-interview-questions/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "Why this Top 50 Data Engineering Interview Questions?",
    "answer": "These top 50 data engineering interview questions cover crucial areas to assess a candidate’s competency and understanding of the field. They span fundamental concepts, technical skills, and practical applications necessary for data engineering roles.",
    "source": "https://www.geeksforgeeks.org/data-engineering/top-50-data-engineering-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Data Engineering, and How Does it Differ from Data Science?",
    "answer": "Data engineering focuses on designing, building, and maintaining the infrastructure and systems needed to collect, store, and process data. Data scientists, on the other hand, analyze this data to gain insights, build models, and support decision-making processes. In essence, data engineers provide the tools and systems, while data scientists use these tools to interpret and analyze data.",
    "source": "https://www.geeksforgeeks.org/data-engineering/top-50-data-engineering-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "2.What is the Difference Between a Data Engineer and a Data Scientist?",
    "answer": "Data modeling is the process of creating a visual representation of an information system or database. It involves defining data elements and their relationships to help design the structure of the database.",
    "source": "https://www.geeksforgeeks.org/data-engineering/top-50-data-engineering-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "4.What are the Different Frameworks and Applications Used by a Data Engineer?",
    "answer": "Data modeling is the process of creating a visual representation of an information system or database. It involves defining data elements and their relationships to help design the structure of the database.",
    "source": "https://www.geeksforgeeks.org/data-engineering/top-50-data-engineering-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "5.What is Data Modelling?",
    "answer": "Data modeling is the process of creating a visual representation of an information system or database. It involves defining data elements and their relationships to help design the structure of the database.",
    "source": "https://www.geeksforgeeks.org/data-engineering/top-50-data-engineering-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "6.What are the Design Schemas of Data Modelling?",
    "answer": "A typical data warehouse architecture includes:",
    "source": "https://www.geeksforgeeks.org/data-engineering/top-50-data-engineering-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "8.What are the Various Methods and Tools Available for Extracting Data in ETL Processes?",
    "answer": "A typical data warehouse architecture includes:",
    "source": "https://www.geeksforgeeks.org/data-engineering/top-50-data-engineering-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "9. What are the Essential Skills Required to be a Data Engineer?",
    "answer": "A typical data warehouse architecture includes:",
    "source": "https://www.geeksforgeeks.org/data-engineering/top-50-data-engineering-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Data Engineering?",
    "answer": "Take Your Data Scientist Skills to the Next LevelWith the Data Scientist Masterâs Program from IBMExplore Program",
    "source": "https://www.simplilearn.com/data-engineer-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "2. Why did you choose a career in Data Engineering?",
    "answer": "An interviewer might ask this question to learn more about your motivation and interest behind choosing data engineering as a career. They want to employ individuals who are passionate about the field. You can start by sharing your story and insights you have gained to highlight what excites you most about being a data engineer.Â",
    "source": "https://www.simplilearn.com/data-engineer-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "3. How does a data warehouse differ from an operational database?",
    "answer": "This data engineer interview question may be more geared toward those on the intermediate level, but in some positions, it may also be considered an entry-level question. Youâll want to answer by stating that databases usingDelete SQL statements, Insert, and Update is standard operational databases that focus on speed and efficiency. As a result, analyzing data can be a little more complicated. With a data warehouse, on the other hand, aggregations, calculations, and select statements are the primary focus. These makedata warehousesan ideal choice fordata analysis.",
    "source": "https://www.simplilearn.com/data-engineer-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "4. What Do *args and **kwargs Mean?",
    "answer": "If youâre interviewing for a more advanced role, you should be prepared to answer complex coding questions. This specific coding question is commonly asked in data engineering interviews, and youâll want to answer by telling your interviewer that *args defines an ordered function and that **kwargs represent unordered arguments used in a function. To impress your interviewer, you may want to write down this code in a visual example to demonstrate your expertise.",
    "source": "https://www.simplilearn.com/data-engineer-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "5. As a data engineer, how have you handled a job-related crisis?",
    "answer": "Data engineers have a lot of responsibilities, and itâs a genuine possibility that youâll face challenges while on the job, or even emergencies. Just be honest and let them know what you did to solve the problem. If you have yet to encounter an urgent issue while on the job or this is your first data engineering role, tell your interviewer what you would do in a hypothetical situation. For example, you can say that if data were to get lost or corrupted, you would work with IT to make sure data backups were ready to be loaded, and that other team members have access to what they need.",
    "source": "https://www.simplilearn.com/data-engineer-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "6. Do you have any experience with data modeling?",
    "answer": "Unless you are interviewing for an entry-level role, you will likely be asked this question at some point during your interview. Start with a simple yes or no. Even if you donât have experience withdata modeling,youâll want to be at least able to define it: the act of transforming and processing fetched data and then sending it to the right individual(s). If you are experienced, you can go into detail about what youâve done specifically. Perhaps you used tools like Talend, Pentaho, or Informatica. If so, say it. If not, simply being aware of the relevant industry tools and what they do would be helpful.",
    "source": "https://www.simplilearn.com/data-engineer-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "7. Why are you interested in this job, and why should we hire you?Â",
    "answer": "It is a fundamental data engineer interview question, but your answer can set you apart from the rest. To demonstrate your interest in the job, identify a few exciting features of the job, which makes it an excellent fit for you and then mention why you love the company.Â",
    "source": "https://www.simplilearn.com/data-engineer-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "8. What are the essential skills required to be a data engineer?",
    "answer": "Every company can have its own definition of a data engineer, and they match your skills and qualifications with the company's assessment.Â",
    "source": "https://www.simplilearn.com/data-engineer-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Apache Spark",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are the types of ETL testing?",
    "answer": "Following are the types of ETL testing.",
    "source": "https://www.geeksforgeeks.org/software-testing/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What are tools used in ETL?",
    "answer": "There are manual and automated methods for testing the performance of an ETL process. For manual testing, SQL query testing is the most used way. However, the procedure is difficult, time-consuming, and prone to errors. As a result, several organizations have started using automated ETL testing technologies. These tools save time while also ensuring accuracy.",
    "source": "https://www.geeksforgeeks.org/software-testing/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "5.What is the importance of ETL testing?",
    "answer": "Following are the importance of ETL testing:",
    "source": "https://www.geeksforgeeks.org/software-testing/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "6.Explain ETL Pipeline?",
    "answer": "An ETL pipeline is a set of operations that transport data from one or more sources to a database, such as a data warehouse. ETL stands for \"extract, transform, load,\" which refers to the three interdependent data integration operations that move data from one database to another.",
    "source": "https://www.geeksforgeeks.org/software-testing/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What are the roles and responsibilities of an ETL tester?",
    "answer": "Following are the role and responsibilities of an ETL tester",
    "source": "https://www.geeksforgeeks.org/software-testing/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "9.  What is BI (Business Intelligence)?",
    "answer": "Business intelligencerefers to a collection of mathematical models and analysis methods that utilize data to produce valuable information and insight for making important decisions. BI test validates staging data, the ETL process, and BI reports to ensure their reliability. Essentially, BI involves gathering raw business data and converting it into actionable insights. BI Testing verifies the accuracy and credibility of these insights derived from the BI process.",
    "source": "https://www.geeksforgeeks.org/software-testing/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "11. What types of data sources can you test in ETL testing?",
    "answer": "In ETL (Extract, Transform, Load) testing, various types of data sources can be tested to ensure the accuracy, completeness, and integrity of the data as it moves through the ETL process.",
    "source": "https://www.geeksforgeeks.org/software-testing/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "13. What do you mean by data purging?",
    "answer": "Data purging refers to the permanent removal of data from a data warehouse or database. Unlike regular deletion, which may temporarily remove data but still keeps it accessible, purging ensures that the data is completely erased and cannot be recovered. This process helps in freeing up storage space and improving system performance by eliminating unnecessary or obsolete data, such as null values or redundant information, thereby optimizing the data warehouse for efficient operations.",
    "source": "https://www.geeksforgeeks.org/software-testing/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "What Do ETL Developers Do?",
    "answer": "ETL developers generally design, automate, develop, and support complex programs that extract, convert, and load data. More specifically, ETL developers are responsible for the following tasks:",
    "source": "https://www.simplilearn.com/etl-testing-interview-questions-article",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What is ETL Testing?",
    "answer": "This is where ETL testing comes into play. ETL is generally recognized as a critical element of data warehouse design in business operations. ETL, or enterprise data integration, takes data from source systems, converts it into a consistent data format, and puts it into a single repository.",
    "source": "https://www.simplilearn.com/etl-testing-interview-questions-article",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What is partitioning?",
    "answer": "Partitioning helps manage database objects better by dividing the storage area and organizing the data more conveniently. When thedata warehouseis partitioned, finding and accessing data is faster.Â Â Â",
    "source": "https://www.simplilearn.com/etl-testing-interview-questions-article",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What is Data Purging?",
    "answer": "Data purging is the process of permanently deleting and removing data from the data warehouse. Eliminating unwanted data frees up storage and memory space.Â Â",
    "source": "https://www.simplilearn.com/etl-testing-interview-questions-article",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "11. What is a factless table?",
    "answer": "A factless table is a table that does not have any facts or measures. Its purpose is to demonstrate relationships between dimensions. A factless table does not hold text or numeric data.",
    "source": "https://www.simplilearn.com/etl-testing-interview-questions-article",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "12. What is Slowly Changing Dimensions (SCD)?",
    "answer": "Slowly Changing Dimensions (SCD) are dimensions that store and manage current and past data in a data warehouse. This data in SCD changes very slowly over time and does not change as per any predefined schedule.Â",
    "source": "https://www.simplilearn.com/etl-testing-interview-questions-article",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "13. What is a data source view?",
    "answer": "A data source view defines the relational schema that is used to carry out analysis in the databases. Cubes and dimensions can also be created using the data source view instead of being built from data source objects. This allows users to construct dimensions inherently and offers superior control over the data structures.",
    "source": "https://www.simplilearn.com/etl-testing-interview-questions-article",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "15. What is BI (Business Intelligence)?",
    "answer": "Business Intelligence refers to gathering, storage, and analysis of data with the objective of converting raw data into actionable information which can be used to make better business decisions.",
    "source": "https://www.simplilearn.com/etl-testing-interview-questions-article",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "What is ETL Testing?",
    "answer": "ETL testing is made easier when a testing strategy is well defined. The ETL testing process goes through different phases, as illustrated below:",
    "source": "https://www.interviewbit.com/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What are the roles and responsibilities of an ETL tester?",
    "answer": "Since ETL testing is so important, ETL testers are in great demand. ETL testers validate data sources, extract data, apply transformation logic, and load data into target tables. The following are key responsibilities of an ETL tester:",
    "source": "https://www.interviewbit.com/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What is the importance of ETL testing?",
    "answer": "Following are some of the notable benefits that are highlighted while endorsing ETL Testing:",
    "source": "https://www.interviewbit.com/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What are different types of ETL testing?",
    "answer": "Before you begin the testing process, you need to define the right ETL Testing technique. It is important to ensure that the ETL test is performed using the right technique and that all stakeholders agree to it. Testing team members should be familiar with this technique and the steps involved in testing. Below are some types of testing techniques that can be used:",
    "source": "https://www.interviewbit.com/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What do you mean by ETL Pipeline?",
    "answer": "As the name suggests, ETL pipelines are the mechanisms to perform ETL processes. This involves a series of processes or activities required for transferring data from one or more sources into the data warehouse for analysis, reporting and data synchronization. It is important to move, consolidate, and alter source data from multiple systems to match the parameters and capabilities of the destination database in order to provide valuable insights.",
    "source": "https://www.interviewbit.com/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What is BI (Business Intelligence)?",
    "answer": "Data validation is involved in both ETL testing and database testing, however, the two are different. The ETL testing procedure normally involves analyzing data stored in a warehouse system. On the other hand, thedatabase testingprocedure is commonly used to analyze data stored in transactional systems. The following are the distinct differences between ETL testing and Database testing.",
    "source": "https://www.interviewbit.com/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What is data source view?",
    "answer": "Using the Data Source View Wizard to create a DSV",
    "source": "https://www.interviewbit.com/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "13. What do you mean by data purging?",
    "answer": "Both data mining and data warehousing are powerful data analysis and storage techniques.",
    "source": "https://www.interviewbit.com/etl-testing-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is an aggregate table in a Data warehouse?",
    "answer": "An aggregate table is a table that contains existing warehouse data grouped to a certain level of dimensions. It is much easier to retrieve data from an aggregated table than the original table, which has more records.",
    "source": "https://www.simplilearn.com/tutorials/data-analytics-tutorial/data-warehouse-interview-questions",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What do you understand by metadata in Data warehouse?",
    "answer": "Data about the data is called metadata. The metadata includes fixed width and limited width, number of columns used, data types, and fields' ordering.",
    "source": "https://www.simplilearn.com/tutorials/data-analytics-tutorial/data-warehouse-interview-questions",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What do you understand by Star Schema?",
    "answer": "Star Schema is the management of the table so that results can be recovered readily in the data warehouse environment.",
    "source": "https://www.simplilearn.com/tutorials/data-analytics-tutorial/data-warehouse-interview-questions",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What is the difference between agglomerative clustering and divisive hierarchical clustering?",
    "answer": "In the agglomerative hierarchical clustering methods, clusters are read from bottom to top. In this method, each object builds its cluster, and these clusters make a large cluster. There is continuous merging until a single large cluster is created. At the same time, divisive hierarchical clustering uses a top to bottom approach. In this method, the division of clusters occurs. The division of parent clusters continues until each cluster has a single object.",
    "source": "https://www.simplilearn.com/tutorials/data-analytics-tutorial/data-warehouse-interview-questions",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What are the testing phases in a project?",
    "answer": "There are five stages of an ETL test- identification of requirements and data sources, acquisition ofdata, implementation of business logic, building and publishing of data, and reporting.",
    "source": "https://www.simplilearn.com/tutorials/data-analytics-tutorial/data-warehouse-interview-questions",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What do you understand by data mart?",
    "answer": "Data mart includes the subset of organization-wide data. This subset of data is insightful to specific groups in an organization. In simple words, we can say that the data mart contains group-specific data.",
    "source": "https://www.simplilearn.com/tutorials/data-analytics-tutorial/data-warehouse-interview-questions",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What are the functions of a warehouse manager?",
    "answer": "A warehouse manager is responsible for performing referential integrity and consistency checks to create business views, indexes, and partition views against the base data. The warehouse manager merges and transforms the source data into the temporary store, backs up the data into the data warehouse, and archives the data at the ends of the captured life.",
    "source": "https://www.simplilearn.com/tutorials/data-analytics-tutorial/data-warehouse-interview-questions",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "12. What do you understand by Hybrid SCD?",
    "answer": "A combination of both SCD1 and SCD2 is called Hybrid SCD. For tables in which some columns (some type 1 and some type 2) are essential, and we need to track its changes, i.e., capture their historical data, we implement Hybrid SCDs.",
    "source": "https://www.simplilearn.com/tutorials/data-analytics-tutorial/data-warehouse-interview-questions",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "What is Data Warehouse?",
    "answer": "Data warehousing (DW) is a method of gathering andanalysing datafrom many sources in order to get useful business insights. Typically, a data warehouse is used to integrate and analyse corporate data from many sources. The data warehouse is the heart of the business intelligence (BI) system, which is designed to analyse and report on data.",
    "source": "https://www.interviewbit.com/data-warehouse-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What do you understand about metadata and why is it used for?",
    "answer": "When a piece of information is placed in the correct context, it takes on a whole new meaning. Furthermore, better-organized Metadata will considerably reduce search time.",
    "source": "https://www.interviewbit.com/data-warehouse-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What do you understand about a data cube in the context of data warehousing?",
    "answer": "A data cube is a multidimensional data model that stores optimized, summarized, or aggregated data for quick and easy analysis using OLAP technologies. The precomputed data is stored in a data cube, which makes online analytical processing easier. We all think of a cube as a three-dimensional structure, however in data warehousing, an n-dimensional data cube can be implemented. A data cube stores information in terms of dimensions and facts.",
    "source": "https://www.interviewbit.com/data-warehouse-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What do you mean by snowflake schema in the context of data warehousing?",
    "answer": "Snowflake Schema is a multidimensional model that is also used in data warehouses. The fact tables, dimension tables, and sub dimension tables are all contained in the snowflake schema. With fact tables, dimension tables, and sub-dimension tables, this schema forms a snowflake.",
    "source": "https://www.interviewbit.com/data-warehouse-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What do you mean by data mining? Differentiate between data mining and data warehousing.",
    "answer": "Following are thedifferences between data warehousing and data mining:-",
    "source": "https://www.interviewbit.com/data-warehouse-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What are the characteristics of a data warehouse?",
    "answer": "Following are the characteristics of a data warehouse:-",
    "source": "https://www.interviewbit.com/data-warehouse-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "11. What do you mean by a factless fact table in the context of data warehousing?",
    "answer": "A fact table with no measures is known as a factless fact table. It's essentially a crossroads of dimensions (it contains nothing but dimensional keys). One form of factless table is used to capture an event, while the other is used to describe conditions.",
    "source": "https://www.interviewbit.com/data-warehouse-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "13. What are the different types of data marts in the context of data warehousing?",
    "answer": "Following are the different types of data mart in data warehousing:",
    "source": "https://www.interviewbit.com/data-warehouse-interview-questions/",
    "role": "Data Engineer",
    "skill": "ETL",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is MLOps?",
    "answer": "MLOps, or Machine Learning Operations, is a set of practices that aim to streamline the process of deploying, managing, and monitoring machine learning models in production. It integrates machine learning system development and operations, facilitating collaboration between data scientists and IT operations teams. MLOps is essential for ensuring that models are reliable, scalable, and continuously updated based on new data and changing business needs.",
    "source": "https://www.geeksforgeeks.org/machine-learning/comprehensive-mlops-interview-questions-from-basic-to-advanced/",
    "role": "Data Engineer",
    "skill": "Airflow",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are the key differences between traditional software development and machine learning development?",
    "answer": "Traditional software development involves writing deterministic code that produces consistent outputs for the same inputs, with a focus on logic and algorithms. In contrast, machine learning development relies on training models using data, which introduces variability. This means machine learning requires continuous monitoring, updating, and retraining to maintain model performance over time, especially as data distributions shift.",
    "source": "https://www.geeksforgeeks.org/machine-learning/comprehensive-mlops-interview-questions-from-basic-to-advanced/",
    "role": "Data Engineer",
    "skill": "Airflow",
    "search_strategy": "direct"
  },
  {
    "question": "3. What are the main components of an MLOps pipeline?",
    "answer": "An MLOps pipeline typically includes several key components:",
    "source": "https://www.geeksforgeeks.org/machine-learning/comprehensive-mlops-interview-questions-from-basic-to-advanced/",
    "role": "Data Engineer",
    "skill": "Airflow",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is the role of version control in MLOps?",
    "answer": "Version control is critical in MLOps as it enables teams to track and manage changes to both code and datasets over time. This facilitates collaboration, allows for easy rollbacks to previous versions, and ensures that experiments can be reproduced. Version control enhances accountability and reproducibility in machine learning projects, which is essential for auditing and compliance.",
    "source": "https://www.geeksforgeeks.org/machine-learning/comprehensive-mlops-interview-questions-from-basic-to-advanced/",
    "role": "Data Engineer",
    "skill": "Airflow",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is data versioning, and why is it important in MLOps?",
    "answer": "Data versioning involves tracking changes to datasets, which is crucial for managing the lifecycle of machine learning models. As models are sensitive to the data they are trained on, maintaining versions of datasets allows teams to experiment with different configurations and revert to earlier versions if needed. This practice ensures consistency, reproducibility, and better management of data quality over time.",
    "source": "https://www.geeksforgeeks.org/machine-learning/comprehensive-mlops-interview-questions-from-basic-to-advanced/",
    "role": "Data Engineer",
    "skill": "Airflow",
    "search_strategy": "direct"
  },
  {
    "question": "6. What are some popular MLOps tools?",
    "answer": "In the rapidly evolving landscape of machine learning, the role of Machine Learning Operations (MLOps) has emerged as a critical discipline, bridging the gap between modeldevelopmentand production deployment. As organizations strive to leverage data-driven insights, the demand for skilledMLOpsprofessionals has surged. MLOps combines best practices from DevOps with machine learning, emphasizing collaboration, automation, and scalability throughout the ML lifecycle.",
    "source": "https://www.geeksforgeeks.org/machine-learning/comprehensive-mlops-interview-questions-from-basic-to-advanced/",
    "role": "Data Engineer",
    "skill": "Airflow",
    "search_strategy": "direct"
  },
  {
    "question": "7. What is the purpose of model training and validation?",
    "answer": "Model training involves teaching an algorithm to recognize patterns by adjusting its parameters based on input data. Validation assesses how well the trained model performs on a separate, unseen dataset. This step is crucial for ensuring that the model generalizes effectively to new data and does not overfit the training set, thus enhancing its predictive performance in real-world applications.",
    "source": "https://www.geeksforgeeks.org/machine-learning/comprehensive-mlops-interview-questions-from-basic-to-advanced/",
    "role": "Data Engineer",
    "skill": "Airflow",
    "search_strategy": "direct"
  },
  {
    "question": "8. What is a CI/CD pipeline, and how is it relevant to MLOps?",
    "answer": "A CI/CD pipeline, or Continuous Integration/Continuous Deployment pipeline, automates the processes of integrating code changes and deploying applications. In MLOps, this is relevant because it allows for rapid iterations and updates to machine learning models, ensuring that changes are made seamlessly and reliably. Automation helps maintain model quality and facilitates quick responses to new data or changing requirements.",
    "source": "https://www.geeksforgeeks.org/machine-learning/comprehensive-mlops-interview-questions-from-basic-to-advanced/",
    "role": "Data Engineer",
    "skill": "Airflow",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is the role of the offset?",
    "answer": "In partitions, messages are assigned a unique ID number called the offset. The role is to identify each message in the partition uniquely.",
    "source": "https://www.simplilearn.com/kafka-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. Can Kafka be used without ZooKeeper?",
    "answer": "It is not possible to connect directly to the Kafka Server by bypassing ZooKeeper. Any client request cannot be serviced if ZooKeeper is down.",
    "source": "https://www.simplilearn.com/kafka-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. In Kafka, why are replications critical?",
    "answer": "Replications are critical as they ensure published messages can be consumed in the event of any program error or machine error and are not lost.",
    "source": "https://www.simplilearn.com/kafka-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What is a partitioning key?",
    "answer": "Ans. The partitioning key indicates the destination partition of the message within the producer. A hashing based partitioner determines the partition ID when the key is given.",
    "source": "https://www.simplilearn.com/kafka-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is the critical difference between Flume and Kafka?",
    "answer": "Kafka ensures more durability and is scalable even though both are used for real-time processing.",
    "source": "https://www.simplilearn.com/kafka-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. When does QueueFullException occur in the producer?",
    "answer": "QueueFullException occurs when the producer attempts to send messages at a pace not handleable by the broker.",
    "source": "https://www.simplilearn.com/kafka-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What is a partition of a topic in Kafka Cluster?",
    "answer": "Partition is a single piece of Kafka topic. More partitions allow excellent parallelism when reading from the topics. The number of partitions is configured based on per topic.",
    "source": "https://www.simplilearn.com/kafka-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. What do you mean by ISR in Kafka environment?",
    "answer": "ISR is the abbreviation of In sync replicas. They are a set of message replicas that are synced to be leaders.",
    "source": "https://www.simplilearn.com/kafka-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is Apache Kafka?",
    "answer": "Apache Kafka is a distributed streaming platform that allows for publishing, subscribing to, storing, and processing streams of records in real-time. It's designed to handle high-throughput, fault-tolerant, and scalable data pipelines. Kafka is often used for building real-time data pipelines and streaming applications.",
    "source": "https://www.geeksforgeeks.org/apache-kafka/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What are the key components of Kafka?",
    "answer": "The key components of Kafka include:",
    "source": "https://www.geeksforgeeks.org/apache-kafka/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is a topic in Kafka?",
    "answer": "A topic in Kafka is a category or feed name to which records are published. Topics in Kafka are always multi-subscriber; that is, a topic can have zero, one, or many consumers that subscribe to the data written to it. Topics are split into partitions for improved scalability and parallel processing.",
    "source": "https://www.geeksforgeeks.org/apache-kafka/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What is a partition in Kafka?",
    "answer": "A partition is an ordered, immutable sequence of records that is continually appended to. Each partition is a structured commit log, and records in the partitions are each assigned a sequential id number called the offset. Partitions allow Kafka to scale horizontally and provide parallel processing capabilities.",
    "source": "https://www.geeksforgeeks.org/apache-kafka/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is the role of ZooKeeper in Kafka?",
    "answer": "ZooKeeper is used for managing and coordinating Kafka brokers. It serves as a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. ZooKeeper keeps track of the status of Kafka cluster nodes, Kafka topics, and partitions.",
    "source": "https://www.geeksforgeeks.org/apache-kafka/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What is a broker in Kafka?",
    "answer": "A broker is a Kafka server that runs in a Kafka cluster. It receives messages from producers, assigns offsets to them, and commits the messages to storage on disk. It also services consumers, responding to fetch requests for partitions and responding with the messages that have been published.",
    "source": "https://www.geeksforgeeks.org/apache-kafka/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. How does Kafka ensure fault tolerance?",
    "answer": "Kafka ensures fault tolerance through data replication. Each partition is replicated across a configurable number of servers for fault tolerance. One of the servers is designated as the leader, which handles all read and write requests for the partition, while the others are followers that passively replicate the leader.",
    "source": "https://www.geeksforgeeks.org/apache-kafka/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What is the difference between a Kafka consumer and consumer group?",
    "answer": "A Kafka consumer is an application that reads data from Kafka topics. A consumer group is a set of consumers that work together to consume data from one or more topics. The key difference is that each message is delivered to one consumer instance within each subscribing consumer group. This allows for parallel processing and load balancing of topic consumption.",
    "source": "https://www.geeksforgeeks.org/apache-kafka/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What does it mean if a replica is not an In-Sync Replica for a long time?",
    "answer": "A replica that has been out of ISR for a long period of time indicates that the follower is unable to fetch data at the same rate as the leader.",
    "source": "https://www.interviewbit.com/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What are the traditional methods of message transfer? How is Kafka better from them?",
    "answer": "Following are the traditional methods of message transfer:-",
    "source": "https://www.interviewbit.com/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What are the major components of Kafka?",
    "answer": "Following are the major components of Kafka:-",
    "source": "https://www.interviewbit.com/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What do you mean by a Partition in Kafka?",
    "answer": "Kafka topics are separated into partitions, each of which contains records in a fixed order. A unique offset is assigned and attributed to each record in a partition. Multiple partition logs can be found in a single topic. This allows several users to read from the same topic at the same time. Topics can be parallelized via partitions, which split data into a single topic among numerous brokers.",
    "source": "https://www.interviewbit.com/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What do you mean by zookeeper in Kafka and what are its uses?",
    "answer": "Apache ZooKeeper is a naming registry for distributed applications as well as a distributed, open-source configuration and synchronization service. It keeps track of the Kafka cluster nodes' status, as well as Kafka topics, partitions, and so on.",
    "source": "https://www.interviewbit.com/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. Can we use Kafka without Zookeeper?",
    "answer": "Kafka can now be used without ZooKeeper as of version 2.8. The release of Kafka 2.8.0 in April 2021 gave us all the opportunity to try it out without ZooKeeper. However, this version is not yet ready for production and lacks some key features.",
    "source": "https://www.interviewbit.com/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?",
    "answer": "Each partition has an elected leader, and other brokers store a copy that can be used if necessary. Logically, the replication factor cannot be more than the cluster's total number of brokers. An In-Sync Replica (ISR) is a replica that is up to date with the partition's leader.",
    "source": "https://www.interviewbit.com/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What do you understand about a consumer group in Kafka?",
    "answer": "A consumer group in Kafka is a collection of consumers who work together to ingest data from the same topic or range of topics. The name of an application is essentially represented by a consumer group. Consumers in Kafka often fall into one of several categories. The ‘-group' command must be used to consume messages from a consumer group.",
    "source": "https://www.interviewbit.com/kafka-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "Why use Kafka in the first place?",
    "answer": "Let’s look at the problem that inspired Kafka in the first place on Linkedin. The problem is simple: Linkedin was getting a lot of logging data, like log messages, metrics, events, and other monitoring/observability data from multiple services. They wanted to utilize this data in two ways:",
    "source": "https://www.geeksforgeeks.org/apache-kafka/hld-or-high-level-system-design-of-apache-kafka-startup/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "What is Kafka?",
    "answer": "Kafkais anopen-source messaging systemthat was created by LinkedIn and later donated to the Apache Software Foundation. It's built to handle large amounts of data in real time, making it perfect for creating systems that respond to events as they happen.",
    "source": "https://www.geeksforgeeks.org/apache-kafka/apache-kafka/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "Why is Apache Kafka Needed?",
    "answer": "With businesses collectingmassive volumes of datain real time, there is a need for tools that can handle this data efficiently. Kafka solves several key problems:",
    "source": "https://www.geeksforgeeks.org/apache-kafka/apache-kafka/",
    "role": "Data Engineer",
    "skill": "Kafka",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What are the three modes that hadoop can Run?",
    "answer": "Local Mode or Standalone ModeHadoop, by default, is configured to run in a no distributed mode. It runs as a single Java process. Instead of HDFS, this mode utilizes the local file system. This mode is more helpful for debugging, and there isn't any requirement to configure core-site.xml, hdfs-site.xml, mapred-site.xml, masters & slaves. Stand-alone mode is ordinarily the quickest mode in Hadoop.",
    "source": "https://www.interviewbit.com/hadoop-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "6. What are the Limitations of Hadoop 1.0 ?",
    "answer": "Only one NameNode is possible to configure.",
    "source": "https://www.interviewbit.com/hadoop-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "7. Compare the main differences between HDFS (Hadoop Distributed File System ) and Network Attached Storage(NAS) ?",
    "answer": "Hadoop MapReduce is a software framework for processing enormous data sets. It is the main component for data processing in the Hadoop framework. It divides the input data into several parts and runs a program on every data component parallel at one. The word MapReduce refers to two separate and different tasks.",
    "source": "https://www.interviewbit.com/hadoop-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "10. What is shuffling in MapReduce?",
    "answer": "In Hadoop MapReduce, shuffling is used to transfer data from the mappers to the important reducers. It is the process in which the system sorts the unstructured data and transfers the output of the map as an input to the reducer. It is a significant process for reducers. Otherwise, they would not accept any information. Moreover, since this process can begin even before the map phase is completed, it helps to save time and complete the process in a lesser amount of time.",
    "source": "https://www.interviewbit.com/hadoop-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "13. What is an Apache Hive?",
    "answer": "Hive is an open-source system that processes structured data in Hadoop, living on top of the latter for summing Big Data and facilitating analysis and queries. In addition, hive enables SQL developers to write Hive Query Language statements similar to standard SQL statements for data query and analysis. It is created to make MapReduce programming easier because you don’t know and write lengthy Java code.",
    "source": "https://www.interviewbit.com/hadoop-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "14. What is Apache Pig?",
    "answer": "MapReduce needs programs to be translated into map and reduce stages. As not all data analysts are accustomed to MapReduce, Yahoo researchers introduced Apache pig to bridge the gap. Apache Pig was created on top of Hadoop, producing a high level of abstraction and enabling programmers to spend less time writing complex MapReduce programs.",
    "source": "https://www.interviewbit.com/hadoop-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "16. What is Yarn?",
    "answer": "Resource Manager: It runs on a master daemon and controls the resource allocation in the cluster.",
    "source": "https://www.interviewbit.com/hadoop-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "18. What is Apache ZooKeeper?",
    "answer": "Apache Zookeeper is an open-source service that supports controlling a huge set of hosts. Management and coordination in a distributed environment are complex. Zookeeper automates this process and enables developers to concentrate on building software features rather than bother about its distributed nature.",
    "source": "https://www.interviewbit.com/hadoop-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "Read more:What Are the Skills Needed to Learn Hadoop?",
    "answer": "In this blog, we will talk about the Hadoop interview questions that could be asked in a Hadoop interview. We will look into Hadoop interview questions from the entireHadoop ecosystem, which includes HDFS, MapReduce, YARN, Hive, Pig, HBase, and Sqoop.",
    "source": "https://www.simplilearn.com/tutorials/hadoop-tutorial/hadoop-interview-questions",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "1. What are the different vendor-specific distributions of Hadoop?",
    "answer": "The different vendor-specific distributions of Hadoop are Cloudera, MAPR, Amazon EMR, Microsoft Azure, IBM InfoSphere, and Hortonworks (Cloudera).",
    "source": "https://www.simplilearn.com/tutorials/hadoop-tutorial/hadoop-interview-questions",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are the different Hadoop configuration files?",
    "answer": "The different Hadoop configuration files include:",
    "source": "https://www.simplilearn.com/tutorials/hadoop-tutorial/hadoop-interview-questions",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "3. What are the three modes in which Hadoop can run?",
    "answer": "The three modes in which Hadoop can run are :",
    "source": "https://www.simplilearn.com/tutorials/hadoop-tutorial/hadoop-interview-questions",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "4. What are the differences between regular FileSystem and HDFS?",
    "answer": "Regular FileSystem: In regular FileSystem, data is maintained in a single system. If the machine crashes, data recovery is challenging due to low fault tolerance. Seek time is more and hence it takes more time to process the data.",
    "source": "https://www.simplilearn.com/tutorials/hadoop-tutorial/hadoop-interview-questions",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "5. Why is HDFS fault-tolerant?",
    "answer": "HDFS is fault-tolerant because it replicates data on different DataNodes. By default, a block of data is replicated on three DataNodes. The data blocks are stored in different DataNodes. If one node crashes, the data can still be retrieved from other DataNodes.Â",
    "source": "https://www.simplilearn.com/tutorials/hadoop-tutorial/hadoop-interview-questions",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "7. What are the two types of metadata that a NameNode server holds?",
    "answer": "The two types of metadata that a NameNode server holds are:",
    "source": "https://www.simplilearn.com/tutorials/hadoop-tutorial/hadoop-interview-questions",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "8. What is the difference between a federation and high availability?",
    "answer": "There is no limitation to the number of NameNodes and the NameNodes are not related to each other",
    "source": "https://www.simplilearn.com/tutorials/hadoop-tutorial/hadoop-interview-questions",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Big Data, and where does it come from? How does it work?",
    "answer": "Big Data refers to extensive and often complicated data sets so huge that they’re beyond the capacity of managing with conventional software tools. Big Data comprises unstructured and structured data sets such as videos, photos, audio, websites, and multimedia content.",
    "source": "https://www.interviewbit.com/big-data-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are the different Output formats in Hadoop?",
    "answer": "The different Output formats in Hadoop are -",
    "source": "https://www.interviewbit.com/big-data-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "4. What are the three modes that Hadoop can run?",
    "answer": "Local Mode or Standalone Mode:By default, Hadoop is configured to operate in a no distributed mode. It runs as a single Java process. Instead of HDFS, this mode utilizes the local file system. This mode is more helpful for debugging, and there isn't any requirement to configure core-site.xml, hdfs-site.xml, mapred-site.xml, masters & slaves. Standalone mode is ordinarily the quickest mode in Hadoop.",
    "source": "https://www.interviewbit.com/big-data-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is fsck?",
    "answer": "The term fsck stands for File System Check, used by HDFS. It is used to check discrepancies and if there is any difficulty in the file. For instance, if there are any missing blocks in the file, HDFS gets reported through this command.",
    "source": "https://www.interviewbit.com/big-data-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "6. How to deploy a Big Data Model? Mention the key steps involved.",
    "answer": "Deploying a model into aBig Data Platforminvolves mainly three key steps they are,",
    "source": "https://www.interviewbit.com/big-data-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "8. How is HDFS different from traditional NFS?",
    "answer": "NFS (Network File system): A protocol that enables customers to access files over the network. NFS clients would allow files to be accessed as if the files live on the local device, even though they live on the disk of a networked device.",
    "source": "https://www.interviewbit.com/big-data-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "12. How is Hadoop and Big Data related?",
    "answer": "If we talk about Big Data, we do talk aboutHadoopas well. So, this is one of the most critical questions from an interview perspective. That you might surely face. Hadoop is an open-source framework for saving, processing, and interpreting complex, disorganized data sets for obtaining insights and knowledge. So, that is how Hadoop and Big Data are related to each other.",
    "source": "https://www.interviewbit.com/big-data-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "14. What are the 5 V’s in Big Data?",
    "answer": "Volume:A considerable amount of data stored in data warehouses reflects the volume. The data may reach random heights; these large volumes of data need to be examined and processed. Which may exist up to or more than terabytes and petabytes.",
    "source": "https://www.interviewbit.com/big-data-interview-questions/",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is big data? Why is it important?",
    "answer": "Big data is a large set of data that cannot be managed by normal software. It comprises audio, text, video, websites, and multimedia content. Big data is important because it helps make informed decisions, improves the efficiency of operations, and predicts risks and failures even before they arise.Â",
    "source": "https://www.simplilearn.com/big-data-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "2. Can you explain the 5 Vs of big data?",
    "answer": "The five Vs of Big Data are:Â",
    "source": "https://www.simplilearn.com/big-data-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "3. What are the differences between big data and traditional data processing systems?",
    "answer": "Traditional data processing systems are designed for structured data and operate within defined limits. In contrast, big data systems handle large amounts of both structured and unstructured data, leveraging distributed computing and storage for scalability.",
    "source": "https://www.simplilearn.com/big-data-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "4. How does big data drive decision-making in modern businesses?",
    "answer": "Big data helps in decision-making by providing actionable insights from large datasets. It enables data-driven strategies and predictive analytics and enhances the understanding of customer behavior, market trends, and operational efficiency.",
    "source": "https://www.simplilearn.com/big-data-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "5. What are some common challenges faced in big data analysis?",
    "answer": "Challenges include managing data volume, velocity, and variety, ensuring data quality, addressing security concerns, handling real-time processing, and dealing with the complexities of distributed computing environments.",
    "source": "https://www.simplilearn.com/big-data-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "6. How do big data and data analytics differ?",
    "answer": "Big data processes large datasets, while data analytics focuses on extracting insights from data. Big data includes storage and processing, while data analytics focuses on statistical analysis.",
    "source": "https://www.simplilearn.com/big-data-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "7. Can you name various big data technologies and platforms?",
    "answer": "Some big data technologies include:",
    "source": "https://www.simplilearn.com/big-data-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "8. How is data privacy managed in big data?",
    "answer": "Data privacy is managed through encryption, access controls, anonymization techniques, and compliance with regulations such as GDPR. Privacy-preserving methods like differential privacy are also employed.",
    "source": "https://www.simplilearn.com/big-data-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Hadoop",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Docker, and why is it used?",
    "answer": "Docker is an open-source platform for application development, from building to scaling. It is preferred for its ability to accelerate the process of building, sharing, and running applications without requiring environment configuration or management.",
    "source": "https://www.simplilearn.com/tutorials/docker-tutorial/docker-interview-questions",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "2. What is a Docker container?",
    "answer": "A Docker container is a standard software packaging unit that contains code and other dependencies such as system libraries, runtime, system tools, and settings. These speed up the application's running across various environments. In simple terms, Docker can be considered an executable, standalone, and lightweight package.",
    "source": "https://www.simplilearn.com/tutorials/docker-tutorial/docker-interview-questions",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "3. How do you create a Docker container?",
    "answer": "ADocker containercan be created using the âdocker container createâ command in the system command. This command establishes the new container from the specified image without starting it immediately. The newly created container is generated in a âcreatedâ state, writable, and open to running specific commands.",
    "source": "https://www.simplilearn.com/tutorials/docker-tutorial/docker-interview-questions",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "4. How does Docker differ from a virtual machine?",
    "answer": "Docker is a software platform for creating and running Docker containers, while a Virtual Machine refers to the physical machine that runs an operating system.",
    "source": "https://www.simplilearn.com/tutorials/docker-tutorial/docker-interview-questions",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is a Docker image?",
    "answer": "Docker imagesare read-only templates in the form of a blueprint or snapshot. They contain guidelines or instructions for creating a container. These images are standalone and executable files that comprise the dependencies, libraries, and files essential for the container.",
    "source": "https://www.simplilearn.com/tutorials/docker-tutorial/docker-interview-questions",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "6. How do you push and pull Docker images?",
    "answer": "Docker images are stored in Docker Hub. To obtain the image or pull it, the required command is",
    "source": "https://www.simplilearn.com/tutorials/docker-tutorial/docker-interview-questions",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "7. What is a Dockerfile?",
    "answer": "A Dockerfile is a text document comprising all the commands required for image assembly. Users call these commands. Examples of Dockerfile commands include âADDâ, âARGâ, âCOPYâ, âLABELâ, and many more.",
    "source": "https://www.simplilearn.com/tutorials/docker-tutorial/docker-interview-questions",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "8. What is a Docker registry?",
    "answer": "The Docker registry is the centralized storage, management, and distribution system for container images. It comprises Docker repositories that contain different versions of the images. Images from the registry can be accessed through push and pull commands.",
    "source": "https://www.simplilearn.com/tutorials/docker-tutorial/docker-interview-questions",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "What is a Container?",
    "answer": "Docker can be visualized as a big ship (docker) carrying huge boxes of products (containers).",
    "source": "https://www.interviewbit.com/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "Why Learn Docker?",
    "answer": "All these aspects form the core part of DevOps which becomes all the more important for any developer to know these in order to improve productivity, fasten the development along with keeping in mind the factors of application scalability and more efficient resource management.",
    "source": "https://www.interviewbit.com/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "1. How many Docker components are there?",
    "answer": "There are three docker components, they are - Docker Client, Docker Host, and Docker Registry.",
    "source": "https://www.interviewbit.com/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are docker images?",
    "answer": "They are executable packages(bundled with application code & dependencies, software packages, etc.) for the purpose of creating containers. Docker images can be deployed to any docker environment and the containers can be spun up there to run the application.",
    "source": "https://www.interviewbit.com/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is a DockerFile?",
    "answer": "It is a text file that has all commands which need to be run for building a given image.",
    "source": "https://www.interviewbit.com/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "4. Can you tell what is the functionality of a hypervisor?",
    "answer": "A hypervisor is a software that makes virtualization happen because of which is sometimes referred to as the Virtual Machine Monitor. This divides the resources of the host system and allocates them to each guest environment installed.",
    "source": "https://www.interviewbit.com/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "5. What can you tell about Docker Compose?",
    "answer": "It is a YAML file consisting of all the details regarding various services, networks, and volumes that are needed for setting up the Docker-based application. So, docker-compose is used for creating multiple containers, host them and establish communication between them. For the purpose of communication amongst the containers, ports are exposed by each and every container.",
    "source": "https://www.interviewbit.com/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "6. Can you tell something about docker namespace?",
    "answer": "A namespace is basically a Linux feature that ensures OS resources partition in a mutually exclusive manner. This forms the core concept behind containerization as namespaces introduce a layer of isolation amongst the containers. In docker, the namespaces ensure that the containers are portable and they don't affect the underlying host. Examples for namespace types that are currently being supported by Docker – PID, Mount, User, Network, IPC.",
    "source": "https://www.interviewbit.com/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Docker ?",
    "answer": "Dockeris a containerization platform that allows to package an application with all its dependencies into one single entity as single container which can be easily deployed and run on any machine that supports docker.  This makes it easier to devlop , test , deploy applications in different environments. It uses container technology to isolate processes and provide a lightweight, portable solution for application deployment.",
    "source": "https://www.geeksforgeeks.org/devops/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "2. What are the Features of Docker?",
    "answer": "Docker features containerization for providing consistent deployment , using  resources efficient shared kernel utilization, and provides seamless portability across environments. It enhances the security through isolation of containers supporting  versioning and automated builds. It  offers a rich number of pre-built images for streamlined application development and deployment.",
    "source": "https://www.geeksforgeeks.org/devops/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "3. What are the Pros and Cons of Docker?",
    "answer": "We can use this following command to import a pre-exported Docker image into another host:",
    "source": "https://www.geeksforgeeks.org/devops/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "6. Can You tell What is the Functionality of a Hypervisor?",
    "answer": "Ahypervisoris a virtualization software that helps in  running  multiple operating systems (Guest OS) on a single physical host system by providing an isolation between the virtual machines (VMs) and manages their resources.",
    "source": "https://www.geeksforgeeks.org/devops/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "7. Difference between Docker and Virtualization?",
    "answer": "Docker usescontainerizationconcept, which shares the host OS kernel for efficiency and speed whereas Virtualization involves running complete OS instances ( Guest Operating systems ) on a hypervisor, which may have more overhead on using resources. The following figure ilustrate on both the Docker and Virtualization Architectures.",
    "source": "https://www.geeksforgeeks.org/devops/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "8. On What Circumstances Will You Lose Data Stored in a Container?",
    "answer": "The Data in a container can be lost whenever the container is deleted, or if docker non-persistent storage( Ephemeral storage ) is used without proper data management. To make the data  persistent , it is recommended to use Docker volumes or volume binding ( volume mounts )  are recommended.",
    "source": "https://www.geeksforgeeks.org/devops/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "9. What is Docker Hub?",
    "answer": "Docker Hubis container registry that serves as a centralized repository forDocker images.It built for developers and open source contributors to find , use , share and download container images.Docker Hub can be used  either host public repos that can be used for free, ordocker private reposfor teams and enterprises.",
    "source": "https://www.geeksforgeeks.org/devops/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "10. What Command Can You Run to Export a Docker Image As an Archive?",
    "answer": "You can use this following command to export a Docker image as an archive:",
    "source": "https://www.geeksforgeeks.org/devops/docker-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Apache Spark?",
    "answer": "Apache Spark is an open-source distributed processing solution for big data workloads. For rapid queries against any size of data, it uses in-memory caching and efficient query execution. Simply put, Spark is a general-purpose data processing engine that is quick and scalable.",
    "source": "https://www.interviewbit.com/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "2. What is the difference between Spark and MapReduce?",
    "answer": "Spark is a MapReduce improvement in Hadoop. The difference between Spark and MapReduce is that Spark processes and retains data in memory for later steps, whereas MapReduce processes data on the disc. As a result, Spark's data processing speed is up to 100 times quicker than MapReduce for lesser workloads. Spark also constructs a Directed Acyclic Graph (DAG) to schedule tasks and orchestrate nodes throughout the Hadoop cluster, as opposed to MapReduce's two-stage execution procedure.",
    "source": "https://www.interviewbit.com/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is the Heartbeat in Hadoop?",
    "answer": "The heartbeat is a communication link that runs between the Namenode and the Datanode. It's the signal that the Datanode sends to the Namenode at regular intervals. If a Datanode in HDFS fails to send a heartbeat to Namenode after 10 minutes, Namenode assumes the Datanode is unavailable.",
    "source": "https://www.interviewbit.com/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "6. What are the design schemas available in data modeling?",
    "answer": "There are two design schemas available in data modeling:",
    "source": "https://www.interviewbit.com/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "7. What is the difference between a data engineer and a data scientist?",
    "answer": "Data science is a broad topic of research. It focuses on extracting data from extremely huge datasets (sometimes it is known as \"big data\").Data scientistscan operate in a variety of fields, including industry, government, and applied sciences. All data scientists have the same goal: to analyze data and derive insights from it that are relevant to their field of work.",
    "source": "https://www.interviewbit.com/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "9. What are the features of Hadoop?",
    "answer": "Hadoop has the following features:",
    "source": "https://www.interviewbit.com/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "10. Which frameworks and applications are important for data engineers?",
    "answer": "SQL, Amazon Web Services, Hadoop, and Python are all required skills for data engineers. Other tools critical for data engineers are PostgreSQL, MongoDB, Apache Spark, Apache Kafka, Amazon Redshift, Snowflake, and Amazon Athena.",
    "source": "https://www.interviewbit.com/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "11. What is HDFS?",
    "answer": "HDFS is an acronym for Hadoop Distributed File System. It is a distributed file system that runs on commodity hardware and can handle massive data collections.",
    "source": "https://www.interviewbit.com/data-engineer-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "What are Docker, Containers, and Images?",
    "answer": "Docker:Docker indata scienceis a part of the main work that count time in accordance os the need of data scientists. Docker employs the concept of reusable content in accordance with the framework that is worth it.",
    "source": "https://www.geeksforgeeks.org/data-engineering/docker-for-data-science/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "Why Docker for Data Scientists?",
    "answer": "Docker offers various benefits for data scientists such as :",
    "source": "https://www.geeksforgeeks.org/data-engineering/docker-for-data-science/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "4. What does containerization mean?",
    "answer": "As the term implies, containerization entails packaging together software code along with all the necessary components, such as frameworks, libraries, and other dependencies, in their own container. Among the advantages of containerization is that a container can be viewed as a fully packaged computing environment that can be transported in one piece.",
    "source": "https://www.interviewbit.com/ci-cd-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is the importance of DevOps?",
    "answer": "A robust and flexible product deployment system is essential for organizations to remain competitive in today's digitized world. It is here that theDevOps conceptcomes into play.",
    "source": "https://www.interviewbit.com/ci-cd-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "7. Can you explain the Git branch?",
    "answer": "The Git branch is essentially a separate line of development that can be used for working on a particular feature, usually during development. The use of branches allows developers to code without interfering with the work of other team members.",
    "source": "https://www.interviewbit.com/ci-cd-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "8. What do you mean by Git Repository?",
    "answer": "As part of the software development process, software projects are organized through Git repositories. In the repository, developers can keep track of all the files and changes in the project, so that they can navigate to any point in its history at any time.",
    "source": "https://www.interviewbit.com/ci-cd-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "10. What is Version Control?",
    "answer": "Version control involves the use of a central repository where teammates can commit changes to files and sets of files. The purpose of version control is to track every line of code, and to share, review, and synchronize changes between team members. The following are some of the most popular version control tools:",
    "source": "https://www.interviewbit.com/ci-cd-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "11. Does CI/CD require any programming knowledge?",
    "answer": "As far as CI/CD goes, it does not require any programming language or scripting language to be used. It is not necessary to use any programming or scripting language when you use a GUI-based tool like Azure DevOps (ADO). The use of ARM templates in Azure DevOps requires scripting knowledge. Therefore, it depends on the tools and different ways of setting up CI/CD.",
    "source": "https://www.interviewbit.com/ci-cd-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "12. What are some popular CI/CD tools?",
    "answer": "Some popular CI/CD tools are as follows:",
    "source": "https://www.interviewbit.com/ci-cd-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "14. What is a CI/CD Engineer?",
    "answer": "CI/CD engineers can improve the integration and operation of CI/CD tools as well as ensure quality end-to-end integration systems. CI/CD Engineers would keep teams motivated and lead the charge on CI/CD. It is the CI/CD engineer's responsibility to ensure that CI/CD tools and platforms are functioning correctly within an organization. CI/CD engineers understand how to optimize their teams' development and release processes.",
    "source": "https://www.interviewbit.com/ci-cd-interview-questions/",
    "role": "Data Engineer",
    "skill": "Docker",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Kubernetes?",
    "answer": "This is one of the most basic Kubernetes interview questions, yet one of the most important ones!Kubernetesis an open-source container orchestration tool or system thatÂautomates tasks such as managing, monitoring, scaling, and deploying containerized applications. It can easily manageÂ several containers (since it can handletheÂ  grouping of containers), providingÂ for logical units that can be discovered and managed.",
    "source": "https://www.simplilearn.com/tutorials/kubernetes-tutorial/kubernetes-interview-questions",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What are K8s?Â",
    "answer": "K8s is another term for Kubernetes.",
    "source": "https://www.simplilearn.com/tutorials/kubernetes-tutorial/kubernetes-interview-questions",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is orchestration when it comes to software and DevOps?Â",
    "answer": "Orchestration refers to integrating multiple services that allow them to automate processes or synchronize information promptly. For example, you have six or seven microservices for an application to run. If you place them in separate containers, this would inevitably create obstacles for communication. Orchestration would help in such a situation by enabling all services in individual containers to work seamlessly to accomplish a single goal.",
    "source": "https://www.simplilearn.com/tutorials/kubernetes-tutorial/kubernetes-interview-questions",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. How are Kubernetes and Docker related?",
    "answer": "This is one of the most frequently asked Kubernetes interview questions, where the interviewer might as well ask you to share your experience working with any of them.Docker is an open-sourceplatform used to handle software development. Its main benefit is that it packages the settings and dependencies that the software/application needs to run into a container, which allows for portability and several other advantages. Kubernetes allows for the manual linking and orchestration of several containers, running on multiple hosts that have been created using Docker.Â",
    "source": "https://www.simplilearn.com/tutorials/kubernetes-tutorial/kubernetes-interview-questions",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What are the main differences between the Docker Swarm and Kubernetes?",
    "answer": "Docker Swarm is Dockerâs native, open-source container orchestration platform that is used to cluster and schedule Docker containers. Swarm differs from Kubernetes in the following ways:",
    "source": "https://www.simplilearn.com/tutorials/kubernetes-tutorial/kubernetes-interview-questions",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What is the difference between deploying applications on hosts and containers?",
    "answer": "Deploying Applications consist of an architecture that has an operating system. The operating system will have a kernel that holds various libraries installed on the operating system needed for an application.",
    "source": "https://www.simplilearn.com/tutorials/kubernetes-tutorial/kubernetes-interview-questions",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What are the features of Kubernetes?",
    "answer": "Kubernetesallows the user to control where the server will host the container and how it will launch. Thus, Kubernetes automates various manual processes.Â",
    "source": "https://www.simplilearn.com/tutorials/kubernetes-tutorial/kubernetes-interview-questions",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What are the main components of Kubernetes architecture?",
    "answer": "There are two primary components ofKubernetes Architecture: the master node and the worker node. Each has individual components.",
    "source": "https://www.simplilearn.com/tutorials/kubernetes-tutorial/kubernetes-interview-questions",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "What is Kubernetes?",
    "answer": "Kubernetes is an open-source platform designed to automate deploying, scaling, and operating application containers.Originally developed by Google, it has become the standard for managing containerized workloads and services. Kubernetes provides a robust framework for orchestrating containers across a cluster of machines, abstracting away the complexities of managing individual containers and allowing developers to focus on building and deploying applications.",
    "source": "https://www.geeksforgeeks.org/devops/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is a Pod in Kubernetes?",
    "answer": "A cluster of one or more Linux containers makes up aKubernetes pod, the smallest unit of a Kubernetes application. From the more common scenario of a single container to an advanced use case with numerous tightly coupled containers within a pod, this basic structure allows for an array of designs.",
    "source": "https://www.geeksforgeeks.org/devops/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. How does Kubernetes handle container scaling?",
    "answer": "To automatically scale the workload to match demand, aHorizontal Pod Autoscalingin Kubernetes updates a workload resource (such a deployment or stateful set). Horizontal scaling indicates that more pods are added in response to an increase in load.",
    "source": "https://www.geeksforgeeks.org/devops/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is Kubelet?",
    "answer": "Kubeletis an important component of Kubernetes that manages containers within pods on a node. It registers the node with the control plane and provides resource information. Kubelet keeps an eye on container health and responds to problems—lik isnces of pods that contain a containerized application. Deployments can help to efficiently scale the number of replica pods, enable the rollout of updated code in a controlled manner, or roll back to the earlier deployment version if necessary.",
    "source": "https://www.geeksforgeeks.org/devops/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What is a Service in Kubernetes?",
    "answer": "The idea of the Service is to group a set of Pod endpoints into a single resource. We can configure various ways to access the grouping. By default, we can get a stable clusterIP addressthat the clients inside the cluster can use to contact Pods in Service.",
    "source": "https://www.geeksforgeeks.org/devops/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. How does Kubernetes manage configuration?",
    "answer": "Kubernetes employsConfigMapsand Secrets to manage configuration. ConfigMaps store non-sensitive setup data, while Secrets handles sensitive information like passwords. These resources have different configurations from the application code, making updates easier. ConfigMaps have key-value pairs for different settings that can be accessed as environment variables or mounted files. Sensitive data is securely stored inSecrets, which are applied to the cluster using kubectl. Both ConfigMaps and Secrets are defined inYAML filesand applied to the cluster using kubectl. Kubernetes tracks changes in these resources, triggering updates in Pods without needing changes to the application code.",
    "source": "https://www.geeksforgeeks.org/devops/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What is the role of the kube-proxy in Kubernetes and how does it facilitate communication between Pods?",
    "answer": "The networking part of Kubernetes that enables communication between pods & services is calledKube-proxy, and it may be installed on any cluster node. Its major function is to maintain network rules for service-to-pod mapping, which provides communication to and fromKubernetes clusters.",
    "source": "https://www.geeksforgeeks.org/devops/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "12. What is a ConfigMap?",
    "answer": "AConfigMapis an API object in Kubernetes that is primarily used to store non-confidential data. ConfigMaps are a way for Kubernetes to inject configuration data into application pods, making it easier to manage and update configuration settings and assist in separating configuration from application code.",
    "source": "https://www.geeksforgeeks.org/devops/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "What is Kubernetes?",
    "answer": "Kubernetesis a distributed open-source technology that helps us in scheduling and executing application containers within and across clusters. A Kubernetes cluster consists of two types of resources:",
    "source": "https://www.interviewbit.com/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. How to do maintenance activity on the K8 node?",
    "answer": "Whenever there are security patches available the Kubernetes administrator has to perform the maintenance task to apply the security patch to the running container in order to prevent it from vulnerability, which is often an unavoidable part of the administration. The following two commands are useful to safely drain the K8s node.",
    "source": "https://www.interviewbit.com/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. How to get the central logs from POD?",
    "answer": "This architecture depends upon the application and many other factors. Following are the common logging patterns",
    "source": "https://www.interviewbit.com/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. How to monitor the Kubernetes cluster?",
    "answer": "Prometheus is used for Kubernetes monitoring. The Prometheus ecosystem consists of multiple components.",
    "source": "https://www.interviewbit.com/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What are the various things that can be done to increase Kubernetes security?",
    "answer": "By default, POD can communicate with any other POD, we can set up network policies to limit this communication between the PODs.",
    "source": "https://www.interviewbit.com/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is the role of Load Balance in Kubernetes?",
    "answer": "Load balancing is a way to distribute the incoming traffic into multiple backend servers, which is useful to ensure the application available to the users.",
    "source": "https://www.interviewbit.com/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What’s the init container and when it can be used?",
    "answer": "init containers will set a stage for you before running the actual POD.",
    "source": "https://www.interviewbit.com/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What is PDB (Pod Disruption Budget)?",
    "answer": "Example: YAML Config using minAvailable =>",
    "source": "https://www.interviewbit.com/kubernetes-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is DevOps?",
    "answer": "DevOpsis a software development approach that combines Development (Dev) and IT Operations (Ops) to automate and streamline the software development, testing, deployment, and maintenance process.",
    "source": "https://www.geeksforgeeks.org/devops/devops-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What is a DevOps Engineer?",
    "answer": "ADevOps Engineeris a professional who combines software development (Dev) and IT operations (Ops) skills to improve and streamline the process of developing, testing, and releasing software.",
    "source": "https://www.geeksforgeeks.org/devops/devops-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What are the top programming and scripting languages which is important to learn too become DevOps Engineer?",
    "answer": "For becoming a successful DevOps Engineer it is essential to learn both the programming and scripting languages. You must learn the following languages:",
    "source": "https://www.geeksforgeeks.org/devops/devops-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What is the use of SSH?",
    "answer": "SSH (Secure Shell) is a cryptographic network protocol used to securely connect and communicate between two systems over an unsecured network. It provides encrypted communication, ensuring that data such as passwords and commands cannot be intercepted by attackers.",
    "source": "https://www.geeksforgeeks.org/devops/devops-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is CI/CD?",
    "answer": "CI And CDis the practice of automating the integration of code changes from multiple developers into a single codebase. It is a software development practice where the developers commit their work frequently to the central code repository (Github or Stash).",
    "source": "https://www.geeksforgeeks.org/devops/devops-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "6.What is the difference between Horizontal and Vertical Scaling?",
    "answer": "We will discuss about the difference between horizontal and vertical scaling one-by-one:",
    "source": "https://www.geeksforgeeks.org/devops/devops-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What is the Blue/Green Deployment Pattern?",
    "answer": "Blue Green Deployment is just like we deploy two versions of our application, one is the stable version, and another is a new feature or bug fix let’s say, forwarding a certain percentage of traffic to the second version as well in production to ensure that everything is working fine.",
    "source": "https://www.geeksforgeeks.org/devops/devops-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What's the difference between DevOps & Agile?",
    "answer": "Agile is a method for creating software.",
    "source": "https://www.geeksforgeeks.org/devops/devops-interview-questions/",
    "role": "Data Engineer",
    "skill": "Kubernetes",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What Is AWS And Why Is It So Popular?",
    "answer": "Amazon Web Services (AWS)is an important cloud computing platform known for its wide service offerings. Its popularity is developed through its scalability, cost-effectiveness, and global infrastructure. Businesses increased the AWS to efficiently scale operations, reduce costs, and innovate rapidly.",
    "source": "https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "3. What Is An EC2 Instance And How Does It Work?",
    "answer": "AnEC2 instanceis essentially a virtual server running in the AWS cloud. When you \"launch\" an EC2 instance, you're setting up a virtual machine with the operating system and software stack you've selected (e.g., a Linux server with Apache).",
    "source": "https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "5. How Does Auto Scaling Work In AWS?",
    "answer": "Auto Scalingis like having an intelligent traffic manager for your application. It automatically adjusts the number of EC2 instances running your application based on real-time traffic demands and predefined policies. For instance, during the high traffic periods,Auto Scaling adds instances, improving optimal performance as per the policies configuration. Conversely, while during low traffic, it will reduce the number of instances , optimizes the cost efficiency maintaining high availability.",
    "source": "https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "6. What Is The AWS Free Tier, And What Services Are Included?",
    "answer": "TheAWS Free Tierprovides a set of AWS services for limited at no cost for the duration of 12 months. The services include EC2, S3, Lambda etc.. This helps the users to explore and experiment with AWS services without suffering with charges and helps in making a kick starting point for cloud beginners.",
    "source": "https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "7. What Are Key-Pairs In AWS?",
    "answer": "A key pair consists of two types of keys - a public key and a private key. The public key is used to encrypt data and stored on the AWS EC2 instance while a private key is used to decrypt data and  is kept by the user. Whenever you want to connect to an AWS EC2 instance a key-pair works as a security credential to prove your secure authentication identity and access to EC2 instance via SSH.",
    "source": "https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "8. What Is Elastic Load Balancing (ELB) And How Does It Function?",
    "answer": "Elastic Load balancer ( ELB )is a service provided by AWS that helps in distribution of incoming traffic of the applications across multi targets such as EC2 instances, containers etc.. in one or more Availability zones. It helps in improving fault tolerance and ensuring the utilization of resources, bringing high availability of the application by preventing a single node ( instance ) faulterance by improving application's resilience.",
    "source": "https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "9. What Are The Various Load Balancers Provided By AWS?",
    "answer": "The following are the types of load balancers provided by AWS:",
    "source": "https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "10. How Is Data Transfer Handled In AWS?",
    "answer": "The data transfer in AWS happens in between regions, within regions, and between the services. It is essential to consider that these data transfer comes with costs when designing the architectures. For example, transfer of the data between an EC2 instance and an S3 bucket within the same region is often free, but the transfer of data in between inter-region comes with charges.",
    "source": "https://www.geeksforgeeks.org/cloud-computing/aws-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "1. Define and explain the three basic types of cloud services and the AWS products that are built based on them?",
    "answer": "The three basic types of cloud services are:",
    "source": "https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "2. What is the relation between the Availability Zone and Region?",
    "answer": "AWS regions are separate geographical areas, like the US-West 1 (North California) and Asia South (Mumbai). On the other hand, availability zones are the areas that are present inside the regions. These are generally isolated zones that can replicate themselves whenever required.",
    "source": "https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is auto-scaling?",
    "answer": "Auto-scalingis a function that allows you to provision and launch new instances whenever there is a demand. It allows you to automatically increase or decrease resource capacity in relation to the demand.",
    "source": "https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is geo-targeting in CloudFront?",
    "answer": "Geo-Targeting is a concept where businesses can show personalized content to their audience based on their geographic location without changing the URL. This helps you create customized content for the audience of a specific geographical area, keeping their needs in the forefront.",
    "source": "https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "5. What are the steps involved in a CloudFormation Solution?",
    "answer": "Here are the steps involved in a CloudFormation solution:",
    "source": "https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "6. How do you upgrade or downgrade a system with near-zero downtime?",
    "answer": "You can upgrade or downgrade a system with near-zero downtime using the following steps of migration:",
    "source": "https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "8. Is there any other alternative tool to log into the cloud environment other than console?",
    "answer": "These can help you log into the AWS resources:",
    "source": "https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "9. What services can be used to create a centralized logging solution?",
    "answer": "The essential services that you can use are Amazon CloudWatch Logs, store them inAmazon S3,and then use Amazon Elastic Search to visualize them. You can use Amazon Kinesis Firehose to move the data from Amazon S3 to Amazon ElasticSearch.",
    "source": "https://www.simplilearn.com/tutorials/aws-tutorial/aws-interview-questions",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is \"AWS Lambda\"?",
    "answer": "Lambda, a software service platform offered by Amazon Web Services, is an example of this type of platform. Lambda enables serverless computing in specific scenarios. Events generated by AWS can be used to initiate the execution of code in any application.",
    "source": "https://www.interviewbit.com/aws-lambda-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "2. Is there a programming language that AWS Lambda is not compatible with?",
    "answer": "AWS Lambda allows for the use of the following programming languages: C#, .NET, Node.js, Javascript, Java (version 8), and Go. These programming languages already have their libraries and other built-in features set up and ready to go.",
    "source": "https://www.interviewbit.com/aws-lambda-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "3. What are the procedures for entering EC2?",
    "answer": "Users are able to connect to EC2 with either a command-line interface or a web-based interface. A further benefit of using AWS lambda is that it equips Windows power shells with the necessary tools.",
    "source": "https://www.interviewbit.com/aws-lambda-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "4. What are the constraints that AWS lambda function imposes?",
    "answer": "AWS Lambda imposes only a few light constraints on the kinds of things that may be done with an operating system and the kinds of programming languages that can be used with it. You cannot simply cease doing things like creating instances, tracking phone calls, or blocking incoming network connections.",
    "source": "https://www.interviewbit.com/aws-lambda-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "5. Which capabilities of AWS lambda contribute to the automation of the deployment process?",
    "answer": "A diverse range of environments is available for use with AWS Lambda. You can use these configurations to retrieve the appropriate data and user credentials in the event that you need to make modifications to your deployment packages, but do not have access to the original packages.",
    "source": "https://www.interviewbit.com/aws-lambda-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is the maximum execution time allowed for an AWS Lambda function to be customised?",
    "answer": "The entirety of the execution will be finished within three hundred seconds of the first user call being made to AWS lambda. The length of timeouts can be customized anywhere from 1 and 300 seconds, with 3 seconds serving as the default value.",
    "source": "https://www.interviewbit.com/aws-lambda-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "7. What are the available frameworks for the serverless approach?",
    "answer": "There are currently a number of powerful serverless frameworks available. They provide outstanding customer service, an open-source whisk, and capabilities for Microsoft Azure, all of which contribute to their product's high level of user-friendliness.",
    "source": "https://www.interviewbit.com/aws-lambda-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "8. For instance, how can Amazon Elastic Compute Cloud (AWS Lambda) guarantee the safety of my programmes?",
    "answer": "The user codes for AWS Lambda can be saved in Amazon S3, and after that, they can be encrypted by following the necessary steps. During the processing, additional tests on the data's integrity are performed by using AWS Lambda.",
    "source": "https://www.interviewbit.com/aws-lambda-interview-questions/",
    "role": "Data Engineer",
    "skill": "AWS",
    "search_strategy": "direct"
  },
  {
    "question": "What is Git and why is it used?",
    "answer": "Git is the most popular, open-source, widely used, and an example of distributed version control system (DVCS) used for handling the development of small and large projects in a more efficient and neat manner.",
    "source": "https://www.interviewbit.com/git-interview-questions/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is a git repository?",
    "answer": "A repository is a file structure where git stores all the project-based files. Git can either stores the files on the local or the remote repository.",
    "source": "https://www.interviewbit.com/git-interview-questions/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "2. What does git clone do?",
    "answer": "The command creates a copy (or clone) of an existing git repository. Generally, it is used to get a copy of the remote repository to the local repository.",
    "source": "https://www.interviewbit.com/git-interview-questions/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "3. What does the command git config do?",
    "answer": "Thegit configcommand is a convenient way to set configuration options for defining the behavior of the repository, user information and preferences, git installation-based configurations, and many such things.For example:To set up your name and email address before using git commands, we can run the below commands:",
    "source": "https://www.interviewbit.com/git-interview-questions/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "4. Can you explain head in terms of git and also tell the number of heads that can be present in a repository?",
    "answer": "Aheadis nothing but a reference to the last commit object of a branch.",
    "source": "https://www.interviewbit.com/git-interview-questions/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is a conflict?",
    "answer": "Git usually handles feature merges automatically but sometimes while working in a team environment, there might be cases of conflicts such as:1. When two separate branches have changes to the same line in a file2. A file is deleted in one branch but has been modified in the other.",
    "source": "https://www.interviewbit.com/git-interview-questions/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is the functionality of git ls-tree?",
    "answer": "This command returns a tree object representation of the current repository along with the mode and the name of each item and the SHA-1 value of the blob.",
    "source": "https://www.interviewbit.com/git-interview-questions/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "7. What does git status command do?",
    "answer": "git statuscommand is used for showing the difference between the working directory and the index which is helpful for understanding git in-depth and also keep track of the tracked and non-tracked changes.",
    "source": "https://www.interviewbit.com/git-interview-questions/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Git?",
    "answer": "Git is adistributed version control system(DVCS) that is used to track changes in source code during software development. It permits multiple developers to work on a project together without interrupting each other's changes.Gitis especially popular for its speed, and ability to manage both small and large projects capably.",
    "source": "https://www.geeksforgeeks.org/git/git-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "2. What is a repository in Git?",
    "answer": "AGit repository(or repo) is like a file structure that stores all the files for a project. It continues track changes made to these files over time, helping teams work together evenly. Git can control both local repositories (on your own machine) and remote repositories (usually hosted on platforms likeGitHub,GitLab, orBitbucket), allowing teamwork and backup.",
    "source": "https://www.geeksforgeeks.org/git/git-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is the difference between Git and GitHub?",
    "answer": "Aliases can be created to simplify Git commands using:",
    "source": "https://www.geeksforgeeks.org/git/git-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is origin in Git?",
    "answer": "In Git, \"origin\" states to the default name offered to the remote repository from which  local repository was cloned.Git originis used as a reference to control fetches, pulls, and pushes.",
    "source": "https://www.geeksforgeeks.org/git/git-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is the purpose of the .gitignore file?",
    "answer": "The'.gitignore'file tells Git which files and folders to ignore when tracking changes. It is used to avoid attaching unneeded files (like logs, temporary files, or compiled code) to your repository. This saves repository clean and targeted on important files only.",
    "source": "https://www.geeksforgeeks.org/git/git-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is a version control system (VCS)?",
    "answer": "Aversion control system(VCS) records the work of developers coordinating on projects. It keeps the history of code changes, permitting developers to add new code, fix bugs, and run tests securely. If required, they can restore a past working version, verifying project security.",
    "source": "https://www.geeksforgeeks.org/git/git-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "7. What is the git push command?",
    "answer": "The 'git push' command is used to share local repository changes to a remote repository. It changes the remote repository with the recent commits from the fixed local branch.",
    "source": "https://www.geeksforgeeks.org/git/git-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "8. What is the git pull command?",
    "answer": "The 'git pull' command updates the current local branch with changes from a remote repository and combining it with a local repository.",
    "source": "https://www.geeksforgeeks.org/git/git-interview-questions-and-answers/",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "What Is Git and Why Is It Used?",
    "answer": "Git is a widely adopted distributed version control system (VCS) essential for managing modifications in source code throughout thesoftware development process. Linus Torvalds developed it in 2005 to facilitate the Linux kernel's development. Engineered for speed and efficiency,Gitis versatile enough to manage projects of any size, from modest to expansive.",
    "source": "https://www.simplilearn.com/tutorials/git-tutorial/git-interview-questions",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "Why Is Git Used?",
    "answer": "Version Control: Git enables several developers to collaborate on a single project at the same time without hindering one another's contributions. It meticulously records every modification to the project's codebase, identifying the author and the timestamp of each change. This functionality is vital for synchronizing team activities and addressing any arising disputes.",
    "source": "https://www.simplilearn.com/tutorials/git-tutorial/git-interview-questions",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Git?",
    "answer": "Git is a decentralized version control system engineered for rapid and effective management of projects ranging from modest to vast in scale. It supports collaborative efforts among developers by monitoring file modifications and enhancing teamwork.",
    "source": "https://www.simplilearn.com/tutorials/git-tutorial/git-interview-questions",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "2. What is a repository in Git?",
    "answer": "AGit repositoryis a location where your project resides, acting as a storage area. This repository can exist locally within a directory on your computer or on a cloud-based platform like GitHub. It encompasses all the files associated with the project, along with a record of the modifications made to these files over time.",
    "source": "https://www.simplilearn.com/tutorials/git-tutorial/git-interview-questions",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is the difference between Git and GitHub?",
    "answer": "Git is a tool for version control that enables you to monitor and record the evolution of your source code. GitHub is an online hosting service that facilitates the management of Git repositories. GitHub offers a user-friendly web interface along with functionalities such as permission management, task organization, error tracking, and the capability to handle feature suggestions.",
    "source": "https://www.simplilearn.com/tutorials/git-tutorial/git-interview-questions",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "4. How does Git work?",
    "answer": "Git works by taking snapshots of a project's files. Unlike other version control systems, Git records the entire contents of each file and its changes every time a commit is made. This makes operations like branching, merging, and reverting changes more efficient.",
    "source": "https://www.simplilearn.com/tutorials/git-tutorial/git-interview-questions",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is a commit in Git?",
    "answer": "In Git, a commit is a process that records a version of the project's presently prepared modifications. This record includes details on the modifications implemented, a distinctive identifier (a SHA-1 hash), the creator's identity, and the timestamp of the commit.",
    "source": "https://www.simplilearn.com/tutorials/git-tutorial/git-interview-questions",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "6. What is branching in Git?",
    "answer": "In Git, branching allows you to veer off from the primary development path and proceed with separate tasks without impacting the main workflow. This technique enables the isolated development of features, bug fixes, or experimentation within a specific section of the repository, ensuring that each process remains distinct from the others.",
    "source": "https://www.simplilearn.com/tutorials/git-tutorial/git-interview-questions",
    "role": "Data Engineer",
    "skill": "Git",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Linux?",
    "answer": "Linus Torvalds developed Linux, a Unix-like, free, open-source, and kernel operating system. Mainly it is designed for systems, servers, embedded devices, mobile devices, and mainframes and is also supported on major computer platforms such as ARM, x86, and SPARC.",
    "source": "https://www.geeksforgeeks.org/linux-unix/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What are the major differences between Linux and Windows?",
    "answer": "The following table will help in understanding the differencesbetween Linux and Windows:",
    "source": "https://www.geeksforgeeks.org/linux-unix/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What is the Linux Kernel? Is it legal to edit it?",
    "answer": "It is known as a low-level software system. TheLinux kerneltracks the resources and provides a user interface. This OS is released under GPL (General Public License). Hence every project is released under it. So, you can edit the Linux kernel legally.",
    "source": "https://www.geeksforgeeks.org/linux-unix/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. What is Shell in Linux?",
    "answer": "Output and input in Linux OS are divided into three standard streams:",
    "source": "https://www.geeksforgeeks.org/linux-unix/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What is a root account?",
    "answer": "The root is like the user's name or system administrator account in Linux. The root account provides complete system control, which an ordinary user cannot do.",
    "source": "https://www.geeksforgeeks.org/linux-unix/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "12. What is Swap Space?",
    "answer": "Linux usesswap spaceto expand RAM. Linux uses this extra space to hold concurrently running programs temporarily.",
    "source": "https://www.geeksforgeeks.org/linux-unix/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "13. What is the difference between hard links and soft links?",
    "answer": "Here is the table that shows thedifference between soft links and hard links:",
    "source": "https://www.geeksforgeeks.org/linux-unix/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "14. How do users create a symbolic link in Linux?",
    "answer": "Symbolic links,symlink, or soft links are shortcuts to files and directories. Users can create the symbolic link in Linux through the' ln' command. The general command to create a symbolic link is as follows:",
    "source": "https://www.geeksforgeeks.org/linux-unix/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "What do you mean by Linux? Explain its features.",
    "answer": "Some important features of Linux OS include:",
    "source": "https://www.interviewbit.com/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is Kernel? Explain its functions.",
    "answer": "A kernel is considered the main component of Linux OS. It is simply a resource manager that acts as a bridge between hardware and software. Its main role is to manage hardware resources for users and is generally used to provide an interface for user-level interaction. A kernel is the first program that is loaded whenever a computer system starts. It is also referred to as low-level system software.",
    "source": "https://www.interviewbit.com/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What are two types of Linux User Mode?",
    "answer": "There are two types of Linux user mode as given below:",
    "source": "https://www.interviewbit.com/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What is swap space?",
    "answer": "Swap space, as the name suggests, is basically a space on a hard disk that is used when the amount of physical memory or RAM is full. It is considered a substitute for physical memory. Its main function is to substitute disk space for RAM memory when real RAM does not have enough space to hold all programs that are executing, and more space is required. In simple words, it can be used as an extension of RAM by Linux.",
    "source": "https://www.interviewbit.com/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What do you mean by a Process States in Linux?",
    "answer": "Linux Process is a type of process that can be in a number of different states. The process enters these states from start till end. Process states in Linux are as follows:",
    "source": "https://www.interviewbit.com/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What is Linux Shell? What types of Shells are there in Linux?",
    "answer": "Linux shell is a user interface present between user and kernel. It is used for executing commands and communication with Linux OS. Linux shell is basically a program used by users for executing commands. It accepts human-readable commands as input and converts them into kernel understandable language.",
    "source": "https://www.interviewbit.com/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What is a maximum length for a filename under Linux?",
    "answer": "The maximum length for a filename under Linux is 255 bytes.",
    "source": "https://www.interviewbit.com/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "12. Under the Linux system, what is the typical size for swap partitions?",
    "answer": "The typical size for a swap partition under a Linux system should be twice the amount of physical memory or RAM available on the system.",
    "source": "https://www.interviewbit.com/linux-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is Linux?",
    "answer": "Linux is a Unix-based open-source operating system. Linus Torvalds was the first to introduce Linux. The primary goal of Linux was to give a free and low-cost operating system for people who couldn't buy Windows, iOS, or Unix.",
    "source": "https://www.simplilearn.com/linux-commands-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. Define Linux Kernel. Is it legal to edit Linux Kernel?",
    "answer": "The Linux Kernel is a low-level software system. It is used to keep track of resources and give a user interface.",
    "source": "https://www.simplilearn.com/linux-commands-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is LILO?",
    "answer": "LILO denotes Linux Loader. It is basically a Linux Boot Loader which loads Linux Operating System into a main memory to start execution. Most of the computer systems are featured with boot loaders for certain versions of Mac OS or Windows OS. So if you want to use Linux OS, you have to install a special boot loader for it.",
    "source": "https://www.simplilearn.com/linux-commands-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What are the basic components of Linux?",
    "answer": "The following are the basic components of Linux:",
    "source": "https://www.simplilearn.com/linux-commands-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. Which shells are used in Linux?",
    "answer": "The following are the most common type of Shells used in Linux:",
    "source": "https://www.simplilearn.com/linux-commands-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What is Swap Space?",
    "answer": "Swap Space is the extra space utilized by Linux to temporarily keep concurrently running processes when RAM space is insufficient. When you start a program, it is stored in RAM so that the CPU can quickly retrieve data. If you have more running programs than RAM can accommodate, the Swap Space is used to store these programs. The processor will now search the RAM and Swap Space for data.",
    "source": "https://www.simplilearn.com/linux-commands-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What command would you use to find out how much memory Linux is using?",
    "answer": "The following are the commands that you can use:",
    "source": "https://www.simplilearn.com/linux-commands-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. What is file permission in Linux?",
    "answer": "The following are the three types of permission in Linux:",
    "source": "https://www.simplilearn.com/linux-commands-interview-questions-article",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is the best way to run a script in the background?",
    "answer": "For a script to run in the background, simply add \"&\" at the end of the command.",
    "source": "https://www.interviewbit.com/shell-scripting-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. How to check whether a link is a hard one or a soft link?",
    "answer": "We can use -h and -L operators of the test command to check whether a link is hard or soft (symbolic link).",
    "source": "https://www.interviewbit.com/shell-scripting-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. Why is a shell script needed?",
    "answer": "Shell scripts can be written for a variety of reasons:",
    "source": "https://www.interviewbit.com/shell-scripting-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What do you mean by Shell variable?",
    "answer": "Shell variables are integral parts of all Shell programs and scripts. In general, we know that variables usually store data either in the form of characters or numbers. Shell also stores and manipulates information using variables in its programs. Generally, shell variables are stored as strings. Variables in the shell provide the information needed for scripts/commands to execute. In the following example, a shell variable is created and then printed:variable =\"Hello\"echo $variable",
    "source": "https://www.interviewbit.com/shell-scripting-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "11. What are different types of variables mostly used in shell scripting?",
    "answer": "Shell scripts usually have two types of variables:",
    "source": "https://www.interviewbit.com/shell-scripting-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "13. What are control instructions?",
    "answer": "Control instructions specify how the different instructions will be executed in the script. They are primarily used to determine the control flow in Shell programs. The execution of a shell script proceeds in succession without these instructions. In shell programs, control instructions govern how execution flows.",
    "source": "https://www.interviewbit.com/shell-scripting-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "14. How many types of control instructions are available in a shell?",
    "answer": "Shells provide four types of control instructions as given below:",
    "source": "https://www.interviewbit.com/shell-scripting-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "16. What is Shell?",
    "answer": "After you press enter, your input is read by the shell. Based on the first word of your input, it determines the command you want to run. The characters in a word are separated using spaces and tabs.",
    "source": "https://www.interviewbit.com/shell-scripting-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What are Data Structures?",
    "answer": "A data structure is a mechanical or logical way that data is organized within a program. The organization of data is what determines how a program performs. There are many types of data structures, each with its own uses. When designing code, we need to pay particular attention to the way data is structured. If data isn't stored efficiently or correctly structured, then the overall performance of the code will be reduced.",
    "source": "https://www.interviewbit.com/data-structure-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. Why Create Data Structures?",
    "answer": "Data structures serve a number of important functions in a program. They ensure that each line of code performs its function correctly and efficiently, they help the programmer identify and fix problems with his/her code, and they help to create a clear and organized code base.",
    "source": "https://www.interviewbit.com/data-structure-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What are some applications of Data structures?",
    "answer": "Following are some real-time applications of data structures:",
    "source": "https://www.interviewbit.com/data-structure-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. Can you explain the difference between file structure and storage structure?",
    "answer": "File Structure:Representation of data into secondary or auxiliary memory say any device such as a hard disk or pen drives that stores data which remains intact until manually deleted is known as a file structure representation.",
    "source": "https://www.interviewbit.com/data-structure-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. Describe the types of Data Structures?",
    "answer": "Linear Data Structure:A data structure that includes data elements arranged sequentially or linearly, where each element is connected to its previous and next nearest elements, is referred to as a linear data structure. Arrays and linked lists are two examples of linear data structures.",
    "source": "https://www.interviewbit.com/data-structure-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What is a stack data structure?  What are the applications of stack?",
    "answer": "Following are some applications for stack data structure:",
    "source": "https://www.interviewbit.com/data-structure-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What are different operations available in stack data structure?",
    "answer": "Some of the main operations provided in the stack data structure are:",
    "source": "https://www.interviewbit.com/data-structure-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. What is a queue data structure?  What are the applications of queue?",
    "answer": "A queue is a linear data structure that allows users to store items in a list in a systematic manner. The items are added to the queue at the rear end until they are full, at which point they are removed from the queue from the front. Queues are commonly used in situations where the users want to hold items for a long period of time, such as during a checkout process. A good example of a queue is any queue of customers for a resource where the first consumer is served first.",
    "source": "https://www.interviewbit.com/data-structure-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. Can you name the important standard streams in the UNIX shell scripting?",
    "answer": "These are Standard Input, Standard Output as well as Standard Error.",
    "source": "https://www.interviewbit.com/unix-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. Name a few significant features of UNIX?",
    "answer": "The following are a few features of UNIX:",
    "source": "https://www.interviewbit.com/unix-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. Can you write a command to erase all files in the current directory including all its sub-directories?",
    "answer": "rm –r* is used to erase all files in the current directory including all its sub-directories. rm is used for deleting files, but with the addition of option -r it erases all files in directories and subdirectories, and finally, an asterisk represents all entries.",
    "source": "https://www.interviewbit.com/unix-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. In Shell scripting, how do you separate the grep and egrep?",
    "answer": "egrep is an extended version of grep, in addition to searching using regular expressions, egrep can use extended regular expressions for searching.$ ls | grep '.env|.json'",
    "source": "https://www.interviewbit.com/unix-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What is the fork() system call?",
    "answer": "This is used to create another process that duplicates the entire process structure and address space. The newly created process is called the child process and the one from which it got replicated is called the parent process. This was used to achieve parallelism before threads. The fork() system call takes no arguments and returns an integer.",
    "source": "https://www.interviewbit.com/unix-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "9.  What is meant by the term Super User?",
    "answer": "The Super User is a user with access to all files and commands within the system. In general, this superuser login is to access root and it is secured with the root password.",
    "source": "https://www.interviewbit.com/unix-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "10. What do chmod, chown, chgrp commands do?",
    "answer": "These are file management commands. These are used for:",
    "source": "https://www.interviewbit.com/unix-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "12. What is the ‘nohup’ in UNIX?",
    "answer": "nohup is a special command to run a process in the background even when a user logs off from the system. It also helps in creating daemon processes or some cleanup script of logs.",
    "source": "https://www.interviewbit.com/unix-interview-questions/",
    "role": "Data Engineer",
    "skill": "Linux",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What Is PostgreSQL, And How Does It Differ From Other SQL Databases?",
    "answer": "PostgreSQL is an open-sourcerelational database management system(RDBMS) that supports bothSQLforrelationaland JSON for non-relational queries. It differs from other SQL databases by offering advanced features like support forcomplex queries,foreign keys,triggers, andupdatableviews. It also supports user-defined types, functions, and operators, which makes it highly extensible.",
    "source": "https://www.geeksforgeeks.org/postgresql/postgresql-interview-questions/",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "2. What Are The Key Features Of PostgreSQL?",
    "answer": "Key features of PostgreSQL include:",
    "source": "https://www.geeksforgeeks.org/postgresql/postgresql-interview-questions/",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "3. How to Create a New Database In PostgreSQL?",
    "answer": "To create a new database in PostgreSQL, you can use theCREATE DATABASEcommand. For example:",
    "source": "https://www.geeksforgeeks.org/postgresql/postgresql-interview-questions/",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "4. How to Create a New Table In PostgreSQL?",
    "answer": "To create a new table in PostgreSQL, you can use theCREATE TABLEcommand. For example:",
    "source": "https://www.geeksforgeeks.org/postgresql/postgresql-interview-questions/",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is a Primary Key in PostgreSQL?",
    "answer": "Aprimary keyis a column or a set of columns that uniquely identifies each row in a table. It ensures that the values in the primary key column(s) areuniqueandnot null. For example:",
    "source": "https://www.geeksforgeeks.org/postgresql/postgresql-interview-questions/",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "6. How to Insert Data Into a Table in PostgreSQL?",
    "answer": "To insert data into a table, you can use theINSERT INTOcommand. For example:",
    "source": "https://www.geeksforgeeks.org/postgresql/postgresql-interview-questions/",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "7. How to Query Data From a Table in PostgreSQL?",
    "answer": "To query data from a table, you can use theSELECTstatement. For example:",
    "source": "https://www.geeksforgeeks.org/postgresql/postgresql-interview-questions/",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "8. What is a Foreign Key in PostgreSQL?",
    "answer": "Aforeign keyis a column or a set of columns that establishes a link between data in two tables. It ensures that the value in the foreign key column matches a value in the referenced column of another table, enforcingreferential integrity. For example:",
    "source": "https://www.geeksforgeeks.org/postgresql/postgresql-interview-questions/",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "1. What does a PostgreSQL partitioned table look like?",
    "answer": "The partitioned table is a logical structure. It is used to split a large table into smaller pieces, which are called partitions.",
    "source": "https://www.simplilearn.com/postgresql-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "2. How can you avoid locking a database unnecessarily?",
    "answer": "We can use MVCC (Multi-version concurrency control) to avoid unnecessary locking of adatabase.",
    "source": "https://www.simplilearn.com/postgresql-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "3. What purpose does pgAdmin serve in PostgreSQL?",
    "answer": "The pgAdmin in PostgreSQL is a data administration tool. It serves the purpose of retrieving, developing, testing, and maintaining databases.",
    "source": "https://www.simplilearn.com/postgresql-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "4. What is the PostgreSQL feature called that splits a large table into smaller pieces?",
    "answer": "It is called table partitioning.",
    "source": "https://www.simplilearn.com/postgresql-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "5. What do you know about PL/Python?",
    "answer": "PL/Pythonis a procedural language to which PostgreSQL provides support.",
    "source": "https://www.simplilearn.com/postgresql-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "6. What methods does PostgreSQL provide to create a new database?",
    "answer": "PostgreSQL provides the following methods to create a new database:",
    "source": "https://www.simplilearn.com/postgresql-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "7. What would be the most important pieces of information you would want to include in a schema?",
    "answer": "A schema contains tables along with data types, views, indexes, operators, sequences, and functions.",
    "source": "https://www.simplilearn.com/postgresql-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "8. What are some of the different operators in PostgreSQL?",
    "answer": "The PostgreSQL operators include: Arithmetic operators, Comparison operators, Logical operators, and Bitwise operators.",
    "source": "https://www.simplilearn.com/postgresql-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "PostgreSQL",
    "search_strategy": "direct"
  },
  {
    "question": "What is MongoDB ?",
    "answer": "MongoDB is an open-source NoSQL database written in C++ language. It uses JSON-like documents with optional schemas.",
    "source": "https://www.interviewbit.com/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What are some of the advantages of MongoDB?",
    "answer": "Some advantages of MongoDB are as follows:",
    "source": "https://www.interviewbit.com/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. When to use MongoDB?",
    "answer": "You should use MongoDB when you are building internet and business applications that need to evolve quickly and scale elegantly. MongoDB is popular with developers of all kinds who are building scalable applications using agile methodologies.MongoDB is a great choice if one needs to:",
    "source": "https://www.interviewbit.com/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What are the data types in MongoDB?",
    "answer": "MongoDB supports a wide range of data types as values in documents. Documents in MongoDB are similar to objects in JavaScript. Along with JSON’s essential key/value–pair nature, MongoDB adds support for a number of additional data types. The common data types in MongoDB are:",
    "source": "https://www.interviewbit.com/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. How to perform queries in MongoDB?",
    "answer": "Thefindmethod is used to perform queries in MongoDB. Querying returns a subset of documents in a collection, from no documents at all to the entire collection. Which documents get returned is determined by the first argument tofind, which is a document specifying the query criteria.",
    "source": "https://www.interviewbit.com/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. How do you Delete a Document?",
    "answer": "The CRUD API in MongoDB providesdeleteOneanddeleteManyfor this purpose. Both of these methods take a filter document as their first parameter. The filter specifies a set of criteria to match against in removing documents.For example:> db.books.deleteOne({\"_id\" : 3})",
    "source": "https://www.interviewbit.com/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. How do you Update a Document?",
    "answer": "Once a document is stored in the database, it can be changed using one of several update methods:updateOne,updateMany, andreplaceOne. updateOneandupdateManyeach takes a filter document as their first parameter and a modifier document, which describes changes to make, as the second parameter.replaceOnealso takes a filter as the first parameter, but as the second parameterreplaceOneexpects a document with which it will replace the document matching the filter.",
    "source": "https://www.interviewbit.com/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. How to add data in MongoDB?",
    "answer": "The basic method for adding data to MongoDB is “inserts”. To insert a single document, use the collection’sinsertOnemethod:",
    "source": "https://www.interviewbit.com/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is MongoDB, and How Does It Differ from Traditional SQL Databases?",
    "answer": "BSON(Binary JSON) is abinary-encoded serializationformat used by MongoDB to store documents. BSON extends JSON by adding support for data types such as dates and binary data and it is designed to be efficient in both storage space and scan speed. The binary format allows MongoDB to be more efficient with data retrieval and storage compared to text-based JSON.",
    "source": "https://www.geeksforgeeks.org/mongodb/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What are Collections And Databases In MongoDB?",
    "answer": "To create a new database and collection in MongoDB, you can use the mongo shell:",
    "source": "https://www.geeksforgeeks.org/mongodb/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. How Does MongoDB Ensure High Availability and Scalability?",
    "answer": "To create a new database and collection in MongoDB, you can use the mongo shell:",
    "source": "https://www.geeksforgeeks.org/mongodb/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What are the Advantages of Using MongoDB Over Other Databases?",
    "answer": "To create a new database and collection in MongoDB, you can use the mongo shell:",
    "source": "https://www.geeksforgeeks.org/mongodb/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. How to Create a New Database and Collection in MongoDB?",
    "answer": "To create a new database and collection in MongoDB, you can use the mongo shell:",
    "source": "https://www.geeksforgeeks.org/mongodb/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "9. What is Sharding, and How Does It Work in MongoDB?",
    "answer": "Shardingis a method for distributing data across multiple servers in MongoDB. It allows for horizontal scaling by splitting large datasets into smaller, more manageable pieces calledshards.",
    "source": "https://www.geeksforgeeks.org/mongodb/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "11. How to Perform Basic Querying in MongoDB?",
    "answer": "Basic querying in MongoDB involves using the find method to retrieve documents that match certain criteria.",
    "source": "https://www.geeksforgeeks.org/mongodb/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "12. What is an Index in MongoDB, and How to Create One?",
    "answer": "Anindexin MongoDB is a data structure that improves the speed of data retrieval operations on a collection. You can create an index using the createIndex method.",
    "source": "https://www.geeksforgeeks.org/mongodb/mongodb-interview-questions/",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "What Is MongoDB?",
    "answer": "MongoDB is a popular open-source, NoSQL (non-relational) database management system that is created to store, retrieve, and manage data flexibly and scalable. MongoDB is classified as a document database, storing data in a format similar to JSON (JavaScript Object Notation) documents.Â",
    "source": "https://www.simplilearn.com/mongodb-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. How does MongoDB differ from traditional relational databases?",
    "answer": "MongoDB is aNoSQL database, while traditional relational databases are SQL-based.",
    "source": "https://www.simplilearn.com/mongodb-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. Can you explain what a document in MongoDB is?",
    "answer": "A document is a JSON-like data structure that stores and represents data. It can contain key-value pairs, arrays, and nested documents. Documents are stored in collections, equivalent to tables in relational databases.",
    "source": "https://www.simplilearn.com/mongodb-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is a collection in MongoDB?",
    "answer": "A collection in MongoDB is a grouping of documents. Collections are schema-less, meaning documents in the same collection can have different structures. Collections are similar to tables in traditional relational databases.",
    "source": "https://www.simplilearn.com/mongodb-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. How does MongoDB store data?",
    "answer": "MongoDB stores data in BSON (Binary JSON) format, a binary-encoded serialization of JSON-like documents. These documents are stored in collections within databases.",
    "source": "https://www.simplilearn.com/mongodb-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What is a primary key in MongoDB?",
    "answer": "In MongoDB, the `_id` field serves as the primary key for a document. It must be unique within a collection and is automatically generated if not provided during document insertion.",
    "source": "https://www.simplilearn.com/mongodb-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. Can you explain the concept of sharding in MongoDB?",
    "answer": "Sharding in MongoDB is a strategy used to distribute data horizontally across numerous servers or clusters, efficiently managing extensive datasets and heavy workloads. In this approach, data is divided into distinct subsets known as shards, and MongoDB's query router directs queries to the relevant shard as needed.",
    "source": "https://www.simplilearn.com/mongodb-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What are indexes in MongoDB?",
    "answer": "MongoDB employs data structures known as indexes to enhance query performance, enabling the database to swiftly locate documents according to the indexed fields. MongoDB offers support for a range of index types.",
    "source": "https://www.simplilearn.com/mongodb-interview-questions-and-answers-article",
    "role": "Data Engineer",
    "skill": "MongoDB",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is Redis and why is it used?",
    "answer": "Redisstands for Remote Dictionary Server. It has become very important in modern application architecture due to its exceptional performance as an in-memory data structure store. It supports a variety of data structures such as strings, hashes, lists, and sets, making it extremely versatile for different programming needs. Interviews for positions involving Redis are becoming more and more common. In this article, we have compiled the most frequently asked Redis interview questions to help you prepare effectively.",
    "source": "https://www.geeksforgeeks.org/system-design/top-25-redis-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "2. How does Redis differ from traditional databases like MySQL?",
    "answer": "Redisstands for Remote Dictionary Server. It has become very important in modern application architecture due to its exceptional performance as an in-memory data structure store. It supports a variety of data structures such as strings, hashes, lists, and sets, making it extremely versatile for different programming needs. Interviews for positions involving Redis are becoming more and more common. In this article, we have compiled the most frequently asked Redis interview questions to help you prepare effectively.",
    "source": "https://www.geeksforgeeks.org/system-design/top-25-redis-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "3. What are Redis hashes?",
    "answer": "Redisstands for Remote Dictionary Server. It has become very important in modern application architecture due to its exceptional performance as an in-memory data structure store. It supports a variety of data structures such as strings, hashes, lists, and sets, making it extremely versatile for different programming needs. Interviews for positions involving Redis are becoming more and more common. In this article, we have compiled the most frequently asked Redis interview questions to help you prepare effectively.",
    "source": "https://www.geeksforgeeks.org/system-design/top-25-redis-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "4. Can Redis be used in a multi-threaded application, and how does it handle concurrency?",
    "answer": "Redisstands for Remote Dictionary Server. It has become very important in modern application architecture due to its exceptional performance as an in-memory data structure store. It supports a variety of data structures such as strings, hashes, lists, and sets, making it extremely versatile for different programming needs. Interviews for positions involving Redis are becoming more and more common. In this article, we have compiled the most frequently asked Redis interview questions to help you prepare effectively.",
    "source": "https://www.geeksforgeeks.org/system-design/top-25-redis-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is pub/sub in Redis?",
    "answer": "Redisstands for Remote Dictionary Server. It has become very important in modern application architecture due to its exceptional performance as an in-memory data structure store. It supports a variety of data structures such as strings, hashes, lists, and sets, making it extremely versatile for different programming needs. Interviews for positions involving Redis are becoming more and more common. In this article, we have compiled the most frequently asked Redis interview questions to help you prepare effectively.",
    "source": "https://www.geeksforgeeks.org/system-design/top-25-redis-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "6. How do you ensure persistence in Redis?",
    "answer": "Redisstands for Remote Dictionary Server. It has become very important in modern application architecture due to its exceptional performance as an in-memory data structure store. It supports a variety of data structures such as strings, hashes, lists, and sets, making it extremely versatile for different programming needs. Interviews for positions involving Redis are becoming more and more common. In this article, we have compiled the most frequently asked Redis interview questions to help you prepare effectively.",
    "source": "https://www.geeksforgeeks.org/system-design/top-25-redis-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "8. What are the main differences between RDB and AOF?",
    "answer": "Redisstands for Remote Dictionary Server. It has become very important in modern application architecture due to its exceptional performance as an in-memory data structure store. It supports a variety of data structures such as strings, hashes, lists, and sets, making it extremely versatile for different programming needs. Interviews for positions involving Redis are becoming more and more common. In this article, we have compiled the most frequently asked Redis interview questions to help you prepare effectively.",
    "source": "https://www.geeksforgeeks.org/system-design/top-25-redis-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "9. How can you scale Redis?",
    "answer": "Redisstands for Remote Dictionary Server. It has become very important in modern application architecture due to its exceptional performance as an in-memory data structure store. It supports a variety of data structures such as strings, hashes, lists, and sets, making it extremely versatile for different programming needs. Interviews for positions involving Redis are becoming more and more common. In this article, we have compiled the most frequently asked Redis interview questions to help you prepare effectively.",
    "source": "https://www.geeksforgeeks.org/system-design/top-25-redis-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "What is System Design?",
    "answer": "It’s impossible to overlook system design when it comes to tech interviews! In the interview, almost every IT giant, whether it’s Facebook, Amazon, Google, or another, asks a series of questions based onSystem Design conceptslike scalability, load balancing, caching, and so on. So without any further adieu, let us go through the most frequently asked interview questions on System Design.",
    "source": "https://www.interviewbit.com/system-design-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is CAP theorem?",
    "answer": "CAP(Consistency-Availability-Partition Tolerance) theorem says that a distributed system cannot guarantee C, A and P simultaneously. It can at max provide any 2 of the 3 guarantees. Let us understand this with the help of a distributed database system.",
    "source": "https://www.interviewbit.com/system-design-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "2. How is Horizontal scaling different from Vertical scaling?",
    "answer": "Horizontal scalingrefers to the addition of more computing machines to the network that shares the processing and memory workload across a distributed network of devices. In simple words, more instances of servers are added to the existing pool and the traffic load is distributed across these devices in an efficient manner.",
    "source": "https://www.interviewbit.com/system-design-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "3. What do you understand by load balancing? Why is it important in system design?",
    "answer": "When a server goes down, the load balancer redirects traffic to the remaining available servers. When a new server gets added to the configuration, the requests are automatically redirected to it. Following are the benefits of load balancers:",
    "source": "https://www.interviewbit.com/system-design-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "4. What do you understand by Latency, throughput, and availability of a system?",
    "answer": "Performance is an important factor in system design as it helps in making our services fast and reliable. Following are the three key metrics for measuring the performance:",
    "source": "https://www.interviewbit.com/system-design-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is Sharding?",
    "answer": "Sharding helps to scale databases by helping to handle the increased load by providing increased throughput, storage capacity and ensuring high availability.",
    "source": "https://www.interviewbit.com/system-design-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "7. How is sharding different from partitioning?",
    "answer": "The following table lists the differences between sharding and partitioning:",
    "source": "https://www.interviewbit.com/system-design-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "9. What is Caching? What are the various cache update strategies available in caching?",
    "answer": "Caching refers to the process of storing file copies in a temporary storage location called cache which helps in accessing data more quickly thereby reducing site latency. The cache can only store a limited amount of data. Due to this, it is important to determine cache update strategies that are best suited for the business requirements. Following are the various caching strategies available:",
    "source": "https://www.interviewbit.com/system-design-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "How Redis Work?",
    "answer": "Redis acts as a caching layer between the database and the client to speed up data access and reduce the load on the main database. When a client asks for data, the API Gateway forwards the request to Redis.",
    "source": "https://www.geeksforgeeks.org/system-design/introduction-to-redis-server/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "When to Use Redis Server?",
    "answer": "Consider you have aMySQLdatabase and you are constantly querying the database which reads the data from the secondary storage, computes the result, and returns the result.",
    "source": "https://www.geeksforgeeks.org/system-design/introduction-to-redis-server/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "Why Redis is so Fast?",
    "answer": "Redis is fast because it keeps all its data in memory instead of on disk, so it doesn’t waste time reading from a hard drive. It also uses just one thread with an event loop to process commands, which avoids the complexity and delays of managing multiple threads.",
    "source": "https://www.geeksforgeeks.org/system-design/introduction-to-redis-server/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is a Database Schema and Why is It Important?",
    "answer": "A database schema is a blueprint orarchitectureof how data is organized in adatabase. It defines the tables, the fields in each table, and therelationshipsbetween fields and tables.",
    "source": "https://www.geeksforgeeks.org/interview-experiences/database-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is CRUD Operations?",
    "answer": "CRUD stands forCreate, Read, Update, Delete, which are the four fundamental operations in database management:",
    "source": "https://www.geeksforgeeks.org/interview-experiences/database-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "4. What are the Different Types of Joins and How do They Work?",
    "answer": "Ensuring data integrity involves using constraints and rules:",
    "source": "https://www.geeksforgeeks.org/interview-experiences/database-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "5. How to Ensure Data Integrity in a Relational Database?",
    "answer": "Ensuring data integrity involves using constraints and rules:",
    "source": "https://www.geeksforgeeks.org/interview-experiences/database-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "7. What are the ACID Properties in a Database and Why are They Important?",
    "answer": "ACID properties ensurereliable transactionprocessing, guaranteedata reliabilityandintegrityin databases.",
    "source": "https://www.geeksforgeeks.org/interview-experiences/database-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "9. What is a Data Warehouse and How is it Different from a Traditional Database?",
    "answer": "To migrate data from an on-premise database to a cloud database:",
    "source": "https://www.geeksforgeeks.org/interview-experiences/database-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "10. How to Handle Data Migration Between Different Databases?",
    "answer": "To migrate data from an on-premise database to a cloud database:",
    "source": "https://www.geeksforgeeks.org/interview-experiences/database-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "11. What is a Relational Database and How does it Differ from a NoSQL Database?",
    "answer": "A relational databases uses structured tables tostore data, with predefinedschemasandrelationships(usually using SQL). It ensures data integrity throughACIDproperties and is suitable forcomplex queriesandtransactions.",
    "source": "https://www.geeksforgeeks.org/interview-experiences/database-interview-questions/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "Can we use Redis as an alternative to the original DB?",
    "answer": "Based on the above discussion, Redis seems to be a better option for the original DB as it provides faster retrievals. Even then Redis isnotused as a primary option for the database in the system.",
    "source": "https://www.geeksforgeeks.org/system-design/redis-and-its-role-in-system-design/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "What is gossiping in the Redis cluster?",
    "answer": "To determine the entire cluster's health, the redis cluster usesgossiping. In the example below, we have 3 main instances and 3 secondary nodes of them. All these nodes constantly determine which nodes are currently available to serve requests. Suppose, if enough shards agree that instance1 is not responsive, they can promote instance1's secondary into a primary to keep the cluster healthy. As a general rule of thumb, it is essential to have an odd number of primary nodes and two replicas each for the most robust and fault-tolerant network.",
    "source": "https://www.geeksforgeeks.org/system-design/redis-and-its-role-in-system-design/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "How AOF works?",
    "answer": "Let us now take a comparative look at the Disadvantages of AOF:",
    "source": "https://www.geeksforgeeks.org/system-design/redis-and-its-role-in-system-design/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "Which one to choose - Real-time database (RDB) or Append Only Files (AOF)?",
    "answer": "The general thought process should be that we use both the persistence methods if we want a degree of data safety comparable to what normal databases like PostgreSQL, can provide us. If we care a lot about our data but still can live with a few minutes of data loss in case of disasters, we can simply use RDB alone.",
    "source": "https://www.geeksforgeeks.org/system-design/redis-and-its-role-in-system-design/",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "Explain what an API endpoint is?",
    "answer": "An API endpoint is a specific URL that acts as an entry point into a specific service or a functionality within a service.Through an API endpoint, client applications can interact with the server sending requests (sometimes even with data in the form of payload) and receive a response from it.Usually, each endpoint can be mapped to a single feature inside the server.",
    "source": "https://roadmap.sh/questions/backend",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "Can you explain the difference between SQL and NoSQL databases?",
    "answer": "SQL databases(or relational databases as they’re also known) rely on a predefined schema (or structure) for their data. Whenever you describe a record, or table inside the database, you do so through its format (name and fields).InNoSQLdatabases, there is no schema, so there is no predefined structure to the data. You usually have collections of records that are not obligated to have the same structure, even if they represent conceptually the same thing.",
    "source": "https://roadmap.sh/questions/backend",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "What is a RESTful API, and what are its core principles?",
    "answer": "For an API to be RESTful (which means it complies with the REST guidelines), it needs to:It needs to follow a client-server architecture (which all HTTP-based services do).It has to provide a uniform interface which means:There should be a way to identify resources from each other through URIs (Unique Resource Identification).There should be a way to modify resources through their representation.Messages should be self descriptive, meaning that each message should provide enough information to understand how to process it.Clients using the API should be able to discover actions available for the current resource using the provided response from the server (this is known as HATEOAS or Hypermedia as the Engine of Application State).It needs to be stateless, which means each request to the server must contain all information to process the request.It should be a layered system, meaning that client and server don’t have to be connected directly to each other, there might be intermediaries,",
    "source": "https://roadmap.sh/questions/backend",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "Can you describe a typical HTTP request/response cycle?",
    "answer": "The HTTP protocol is very structured and consists of a very well-defined set of steps:Open the connection.The client opens a TCP connection to the server. The port will be port 80 for HTTP connections and 443 for HTTPS (secured) connections.Send the request.The client will now send the HTTP request to the server. The request contains the following information:AnHTTP method. It can be any of them (i.e. GET, POST, PUT, DELETE, etc).A URI (or Uniform Resource Identifier). This specifies the location of the resources on the server.The HTTP version (usually HTTP/1.1 or HTTP/2).A set of headers. They include extra data related to the request; there is afull list of HTTP headersthat can be used here.The optional body. Depending on the type of request, you’ll want to also send data, and the data is encoded inside the body of the request.Request processed by the server.At this stage, the server will process the request and prepare a response.Send the HTTP response back to the client.Through the",
    "source": "https://roadmap.sh/questions/backend",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "How would you handle file uploads in a web application?",
    "answer": "From a backend developer perspective, the following considerations should be taken into account when handling file uploads regardless of the programming language you’re using:Perform server-side validations.Validate that the size of your file is within range, and that the file is of the required type. You can checkthis OWASP guidefor more details.Use secure channels.Make sure the file upload is done through an HTTPS connection.Avoid name collision.Rename the file ensuring the new filename is unique within your system. Otherwise this can lead to application errors by not being able to save the uploaded files.Keep metadata about your files.Store it in your database or somewhere else, but make sure to keep track of it, so you can provide extra information to your users. Also, if you’re renaming the files for security and to avoid name collisions, keep track of the original filename in case the file needs to be downloaded back by the user.",
    "source": "https://roadmap.sh/questions/backend",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "What kind of tests would you write for a new API endpoint?",
    "answer": "As backend developers, we have to think about the types of tests that there are out there.Unit tests:Always remember to only test the relevant logic through the public interface of your code (avoid testing private methods or inaccessible functions inside your modules). Focus on the business logic and don’t try to test the code that uses external services (like a database, the disk or anything outside of the piece of code you’re testing).Integration tests:Test the full endpoint through its public interface (the actual HTTP endpoint) and see how it integrates with the external services it’s using (i.e the database, another API, etc).Load testing / performance testing:You might want to also check how the new endpoint behaves under heavy stress. This might not be required depending on the API you’re using, but as a rule of thumb, it’s a good one to perform at the end of the development phase before releasing the new endpoint into prod.",
    "source": "https://roadmap.sh/questions/backend",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "How do you approach API versioning in your projects?",
    "answer": "There are several ways in which you can handle API versioning, but the most common ones are:",
    "source": "https://roadmap.sh/questions/backend",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "How do you protect a server from SQL injection attacks?",
    "answer": "There are many ways to protect your relational database from SQL injection attacks, but here are three very common ones.Prepared statements with parameterized queries.This is probably the most effective way since it’s done by a library or framework, and all you have to do is write your queries leaving placeholders for where the data is meant to go, and then, in a separate place, provide the actual data.Use an ORM (Object-Relational Mapping).These frameworks allow you to abstract the interaction with your database and create the SQL queries for you, taking into account all matters of security around that interaction.Escaping data.If you want to do this manually, you can take care of escaping special characters that might break how you construct your SQL queries. Keeping a list of blacklisted characters to escape in this situation is a good idea, so you can programmatically go through them.",
    "source": "https://roadmap.sh/questions/backend",
    "role": "Data Engineer",
    "skill": "Redis",
    "search_strategy": "direct"
  },
  {
    "question": "What is a Data Model?",
    "answer": "A data model organizes different data elements and standardizes how they relate to one another and real-world entity properties. So logically then, data modeling is the process of creating those data models.",
    "source": "https://www.simplilearn.com/data-modeling-interview-question-and-answers-article",
    "role": "Data Engineer",
    "skill": "Data Warehousing",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What Are the Three Types of Data Models?",
    "answer": "The three types of data models:",
    "source": "https://www.simplilearn.com/data-modeling-interview-question-and-answers-article",
    "role": "Data Engineer",
    "skill": "Data Warehousing",
    "search_strategy": "role_specific"
  },
  {
    "question": "2.Â  What is a Table?",
    "answer": "A table consists of data stored in rows and columns. Columns, also known as fields, show data in vertical alignment. Rows also called a record or tuple, represent dataâs horizontal alignment.",
    "source": "https://www.simplilearn.com/data-modeling-interview-question-and-answers-article",
    "role": "Data Engineer",
    "skill": "Data Warehousing",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is Normalization?",
    "answer": "Database normalizationis the process of designing the database in such a way that it reduces data redundancy without sacrificing integrity.",
    "source": "https://www.simplilearn.com/data-modeling-interview-question-and-answers-article",
    "role": "Data Engineer",
    "skill": "Data Warehousing",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. What Does a Data Modeler Use Normalization For?",
    "answer": "The purposes of normalization are:",
    "source": "https://www.simplilearn.com/data-modeling-interview-question-and-answers-article",
    "role": "Data Engineer",
    "skill": "Data Warehousing",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. So, What is Denormalization, and What is its Purpose?",
    "answer": "Denormalization is a technique where redundant data is added to an already normalized database. The procedure enhances read performance by sacrificing write performance.",
    "source": "https://www.simplilearn.com/data-modeling-interview-question-and-answers-article",
    "role": "Data Engineer",
    "skill": "Data Warehousing",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What Does ERD Stand for, and What is it?",
    "answer": "ERD stands for Entity Relationship Diagram and is a logical entity representation, defining the relationships between the entities. Entities reside in boxes, and arrows symbolize relationships.",
    "source": "https://www.simplilearn.com/data-modeling-interview-question-and-answers-article",
    "role": "Data Engineer",
    "skill": "Data Warehousing",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. Whatâs the Definition of a Surrogate Key?",
    "answer": "A surrogate key, also known as aprimary key, enforces numerical attributes. This surrogate key replaces natural keys. Instead of having primary or composite primary keys, data modelers create the surrogate key, which is a valuable tool for identifying records, buildingSQL queries, and enhancing performance.",
    "source": "https://www.simplilearn.com/data-modeling-interview-question-and-answers-article",
    "role": "Data Engineer",
    "skill": "Data Warehousing",
    "search_strategy": "role_specific"
  },
  {
    "question": "What is Snowflake?",
    "answer": "To satisfy the demanding needs of growing enterprises, Snowflake includes out-of-the-box features such as storage and compute separation, on-the-fly scalable computing, data sharing, data cloning, and third-party tool support, etc. In comparison to traditional solutions, Snowflake delivers fast, easy-to-use, and flexible data storage, processing, and analytics.  A number of programming languages are supported by Snowflake, including Go, C, .NET, Java, Python, Node.js, etc.",
    "source": "https://www.interviewbit.com/snowflake-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "1. What are the essential features of Snowflake?",
    "answer": "Snowflake has the following key features:",
    "source": "https://www.interviewbit.com/snowflake-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "3. What do you mean by virtual warehouse?",
    "answer": "A virtual warehouse is basically a collection of computing resources (like CPU, memory, Solid state drive, etc.) that customers can access to run queries, load data, and perform other DML (Data Manipulation Language) and SQL (Structured Query Language) operations.",
    "source": "https://www.interviewbit.com/snowflake-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "4. Can you tell me how to access the Snowflake Cloud data warehouse?",
    "answer": "Snowflake's data warehouse can be accessed using the following ways:",
    "source": "https://www.interviewbit.com/snowflake-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "5. What is the difference between Snowflake and Redshift?",
    "answer": "Cloud-based data warehouses are becoming increasingly popular, with Redshift and Snowflake being two of the biggest players. These are large data analytics databases capable of analyzing and reading vast amounts of data.",
    "source": "https://www.interviewbit.com/snowflake-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "8. What do you mean by Snowflake Computing?",
    "answer": "The term snowflake computing refers to Snowflake's ability to provide instant, secure, and governed access to all data networks, along with its core architecture that enables multiple types of data workloads and offers a unified platform for modern data applications.  In contrast to other data warehouses, Snowflake does not use a database or \"big data\" software platform such as Hadoop. Snowflake, however, combines an entirely new SQL query engine with a natively cloud-based architecture.",
    "source": "https://www.interviewbit.com/snowflake-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "9. Which cloud platforms does Snowflake currently support?",
    "answer": "Snowflake currently supports the following cloud platforms:",
    "source": "https://www.interviewbit.com/snowflake-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "10. In Snowflake, how are data and information secured?",
    "answer": "Every organization considers data security to be one of its top priorities. The Snowflake platform adheres to the best security standards in the industry to encrypt and safeguard customer data. The platform provides the best key management features at no additional charge. To protect client data, Snowflake employs the following security measures:",
    "source": "https://www.interviewbit.com/snowflake-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Azure Data Factory?",
    "answer": "In today's world, there is an abundance of data coming from a wide range of different sources; collectively, this information forms a gigantic mountain of data. Before we can upload this information to the cloud, there are a few things that need to be taken care of first.",
    "source": "https://www.interviewbit.com/azure-data-factory-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "2. In the pipeline, can I set default values for the parameters?",
    "answer": "Parameters in pipelines can have default values defined.",
    "source": "https://www.interviewbit.com/azure-data-factory-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "3. What is the anticipated length of time needed for the integration?",
    "answer": "The integration runtime of Azure Data Factory is the underlying computational architecture that enables the following data integration functionalities across a range of network topologies. These features can be accessed through the Azure portal.",
    "source": "https://www.interviewbit.com/azure-data-factory-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "4. How many times may an integration be run through its iterations?",
    "answer": "There are no limits placed in any way on the amount of integration runtime instances that can exist within a data factory. However, there is a limit on the number of virtual machine cores that can be utilized by the integration runtime for the execution of SSIS packages for each subscription.",
    "source": "https://www.interviewbit.com/azure-data-factory-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "5. Where can I obtain additional information on the blob storage offered by Azure?",
    "answer": "With the use of a service known as Blob Storage, vast amounts of data belonging to Azure Objects, such as text or binary data, can be saved. Using Blob Storage, you have the option of retaining the confidentiality of the data associated with your application or making it accessible to the general public. The following are some examples of typical applications of Blob Storage:",
    "source": "https://www.interviewbit.com/azure-data-factory-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "6. Is there a cap on the number of cycles that can be invested in the integration process?",
    "answer": "In no way is this the case; an Azure data factory can support an unlimited number of integration runtime occurrences simultaneously. However, there is a maximum number of VM cores that can be used by the integration runtime while executing SSIS packages, and this limitation varies depending on the type of subscription. It is essential that you have a solid grasp of these ideas before you start your journey toward earning a certification in Microsoft Azure.",
    "source": "https://www.interviewbit.com/azure-data-factory-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "7. How does the Data Factory's integration runtime actually function?",
    "answer": "Integration Runtime, a safe computing platform, makes it feasible for Data Factory to offer data integration capabilities that are portable across various network configurations. This is made possible by the use of Integration Runtime. Because of its proximity to the data centre, the work will almost certainly be performed there. If you want to Learn Azure Step by Step, you must be familiar with terminologies like this and other key aspects of Azure.",
    "source": "https://www.interviewbit.com/azure-data-factory-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "9. What are the three different types of triggers that are available for use with Azure Data Factory?",
    "answer": "Utilizing the Schedule trigger helps ensure that the ADF pipeline is executed in accordance with a predetermined timetable.",
    "source": "https://www.interviewbit.com/azure-data-factory-interview-questions/",
    "role": "Data Engineer",
    "skill": "Data Lakes",
    "search_strategy": "direct"
  },
  {
    "question": "1. What is Databricks Spark?",
    "answer": "Databricks Spark is the result of Apache Spark being forked to build it. Spark has undergone development and received upgrades that make its connection with Databricks more streamlined.",
    "source": "https://www.interviewbit.com/azure-databricks-interview-questions/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. What are the advantages of Microsoft Azure Databricks?",
    "answer": "Utilizing Azure Databricks comes with a variety of benefits, some of which are as follows:",
    "source": "https://www.interviewbit.com/azure-databricks-interview-questions/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. Why is it necessary for us to use the DBU Framework?",
    "answer": "The DBU Framework was developed as a means of streamlining the process of developing applications on Databricks that are capable of working with significant quantities of data. A command line interface (CLI), a software development kit (SDK) written in Python, and a software development kit written in Java are all included in the framework (SDK).",
    "source": "https://www.interviewbit.com/azure-databricks-interview-questions/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. When referring to Azure Databricks, what exactly does it mean to \"auto-scale\" a cluster of nodes?",
    "answer": "The auto-scaling feature offered by Databricks enables you to automatically expand or contract the size of your cluster as needed. Utilizing only the resources that are really put to use is a foolproof method for lowering expenses and reducing waste.",
    "source": "https://www.interviewbit.com/azure-databricks-interview-questions/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What actions should I take to resolve the issues I'm having with Azure Databricks?",
    "answer": "If you are having trouble using Azure Databricks, you should begin by looking over the Databricks documentation. The documentation includes a collated list of common issues and the remedies to those issues, as well as any other relevant information. You can also get in touch with the support team for Databricks if you find that you require assistance.",
    "source": "https://www.interviewbit.com/azure-databricks-interview-questions/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. What is the function of the Databricks filesystem?",
    "answer": "The Databricks filesystem is used to store the data that is saved in Databricks. Workloads involving large amounts of data are an ideal fit for this particular distributed file system. The Hadoop Distributed File System (DVFS) is compatible with Databricks, which is a distributed file system (HDFS).",
    "source": "https://www.interviewbit.com/azure-databricks-interview-questions/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. What programming languages are available for use when interacting with Azure Databricks?",
    "answer": "A few examples of languages that can be used in conjunction with the Apache Spark framework include Python, Scala, and R. Additionally, the SQL database language is supported by Azure Databricks.",
    "source": "https://www.interviewbit.com/azure-databricks-interview-questions/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. Is it possible to manage Databricks using PowerShell?",
    "answer": "No, the administration of Databricks cannot be done with PowerShell because it is not compatible with it. There are other methods available, including the Azure command line interface (CLI), the Databricks REST API, and the Azure site itself.",
    "source": "https://www.interviewbit.com/azure-databricks-interview-questions/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "1. What is Azure Databricks, and how does it integrate with Azure?",
    "answer": "Azure Databricks is a data analytics and AI-based service offered byMicrosoft Azure. It unifies data, the data ecosystem, and data teams. It is integrated with multiple Azure environments, such as Azure Data Lake Storage, Power BI, Azure Synapse Analytics, Azure Data Factory, and others, for advanced solutions and enhanced performance.",
    "source": "https://www.simplilearn.com/azure-databricks-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "2. Can you explain the concept of a Databricks cluster and its components?",
    "answer": "Databricks clusters refer to configurations and resources for running jobs and notebooks. There are two types of clusters: all-purpose and jobs.Â",
    "source": "https://www.simplilearn.com/azure-databricks-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "3. What is Apache Spark, and how does Databricks utilize it?",
    "answer": "Apache Sparkis an open-source analytics engine that powers compute clusters and SQL warehouses. Azure Databricks offers a user-friendly, secure, and efficient platform for running Apache Spark workloads.",
    "source": "https://www.simplilearn.com/azure-databricks-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "4. How do you create a workspace in Azure Databricks?",
    "answer": "Workspace can be created in Azure Databricks through any of the following tools: Azure Portal, Azure CLI, PowerShell,ARM template, Bicep, and Terraform. To create a workspace in Azure Databricks, you can follow these steps:",
    "source": "https://www.simplilearn.com/azure-databricks-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "5. What are notebooks in Azure Databricks, and how do they help with data processing?",
    "answer": "Notebooks are the primary tool for code development in different languages and for presenting results. They contribute to data processing by allowing team collaboration, automatic versioning, data analysis, environment customization, text writing in other languages, and built-indata visualizations.",
    "source": "https://www.simplilearn.com/azure-databricks-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "6. How do you scale a cluster in Azure Databricks, and what factors should you consider?",
    "answer": "Scaling can be done in three ways: vertically by adding or removing resources, horizontally by editing the nodes of a distributed system, and linearly by adding resources to a system. Factors influencing scaling include the number of workers, cores, memory, local storage, complexity, data source, data partitioning method in external storage, and the need for parallelism.Â",
    "source": "https://www.simplilearn.com/azure-databricks-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "7. Can you explain how Delta Lake works in Azure Databricks?",
    "answer": "Delta Lake helps store tables in Databricks by incorporating a transaction log on Parquet data files. It enables reliableACID transactionsand efficient and scalable metadata handling.",
    "source": "https://www.simplilearn.com/azure-databricks-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "8. What is the process for migrating a Spark job from a local environment to Azure Databricks?",
    "answer": "The process to migrate the Spark workload to Databricks involves the following steps:",
    "source": "https://www.simplilearn.com/azure-databricks-interview-questions-answers-article",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "Why Databricks?It is commonly used for tasks such as data preparation, real-time analysis, and machine learning. Some examples of how Databricks might be used include:",
    "answer": "Processing large amounts of data from multiple sources, such as web logs, sensor data, or transactional data, in order to gain insights and identify trends.Building and training machine learning models, using tools such as TensorFlow, Keras, and PyTorch, to make predictions or perform other types of data analysis.Real-time data analysis, such as monitoring and analyzing streaming data from sensors or other sources, in order to make timely decisions or take action based on the data.Data preparation, such as cleaning, transforming, and enriching data, in order to make it ready for analysis or other uses.Overall, Databricks is a versatile platform that can be used for a wide range of data-related tasks, from simple data preparation and analysis to complex machine learning and real-time data processing.",
    "source": "https://www.geeksforgeeks.org/devops/introduction-to-databricks/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "Tell your experience with Microsoft Azure for data engineering projects.",
    "answer": "I explained my experience working with Microsoft Azure and mentioned projects where I utilized services like Azure Data Factory, Azure Databricks, Logic Apps and Azure SQL Database to build and manage data pipelines for ETL processes.",
    "source": "https://www.geeksforgeeks.org/interview-experiences/optum-uhg-interview-experience-for-senior-data-engineer-fte/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "How do you ensure data security and compliance when working with sensitive healthcare data on the Azure platform?",
    "answer": "I explained that I have a strong understanding of Azure's security features and compliance standards. Then there were a few follow-up questions around Azure Key Vault, encryption keys, secrets, and RBAC.",
    "source": "https://www.geeksforgeeks.org/interview-experiences/optum-uhg-interview-experience-for-senior-data-engineer-fte/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "Can you discuss your experience with Azure Databricks? How have you used it for big data processing and machine learning tasks?",
    "answer": "I elaborated on a specific project where I leveraged Azure Databricks to process large volumes of healthcare data and perform machine learning tasks for predictive analytics. I explained how Databricks' collaborative workspace and integration with other Azure services facilitated a seamless data engineering and data science workflow.",
    "source": "https://www.geeksforgeeks.org/interview-experiences/optum-uhg-interview-experience-for-senior-data-engineer-fte/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  },
  {
    "question": "How do you manage and optimize costs when running data workloads on Microsoft Azure?",
    "answer": "I explained that I adopt a cost-conscious approach when designing data solutions on Azure. I use Azure Cost Management and Billing to monitor resource consumption and identify areas for optimization. Additionally, I mentioned leveraging serverless technologies like Azure Functions and Azure Logic Apps to scale resources dynamically based on workload demands.",
    "source": "https://www.geeksforgeeks.org/interview-experiences/optum-uhg-interview-experience-for-senior-data-engineer-fte/",
    "role": "Data Engineer",
    "skill": "Databricks",
    "search_strategy": "role_specific"
  }
]